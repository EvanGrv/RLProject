{
  "datetime": "2025-07-21T17:39:35.360089",
  "environnement": "LineWorld",
  "modele": "Monte Carlo ES",
  "hyperparametres": {},
  "resultats_train": {
    "Q": [
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ],
      [
        1.0,
        1.0
      ]
    ],
    "policy": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    "history": [
      {
        "episode": 1,
        "avg_q_value": 0.0625,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 1
      },
      {
        "episode": 50,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 3,
        "num_state_actions_visited": 16
      },
      {
        "episode": 100,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 6,
        "num_state_actions_visited": 16
      },
      {
        "episode": 150,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 7,
        "num_state_actions_visited": 16
      },
      {
        "episode": 200,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 2,
        "num_state_actions_visited": 16
      },
      {
        "episode": 250,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 5,
        "num_state_actions_visited": 16
      },
      {
        "episode": 300,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 16
      },
      {
        "episode": 350,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 3,
        "num_state_actions_visited": 16
      },
      {
        "episode": 400,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 16
      },
      {
        "episode": 450,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 500,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 550,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 5,
        "num_state_actions_visited": 16
      },
      {
        "episode": 600,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 650,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 16
      },
      {
        "episode": 700,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 750,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 6,
        "num_state_actions_visited": 16
      },
      {
        "episode": 800,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 16
      },
      {
        "episode": 850,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 2,
        "num_state_actions_visited": 16
      },
      {
        "episode": 900,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 7,
        "num_state_actions_visited": 16
      },
      {
        "episode": 950,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 5,
        "num_state_actions_visited": 16
      },
      {
        "episode": 1000,
        "avg_q_value": 1.0,
        "max_q_value": 1.0,
        "episode_length": 5,
        "num_state_actions_visited": 16
      }
    ],
    "episodes": 1000,
    "returns_sum": {
      "(0, 0)": 65.0,
      "(1, 0)": 801.0,
      "(2, 0)": 698.0,
      "(3, 0)": 581.0,
      "(4, 0)": 442.0,
      "(1, 1)": 64.0,
      "(5, 0)": 324.0,
      "(4, 1)": 67.0,
      "(2, 1)": 75.0,
      "(7, 1)": 66.0,
      "(6, 1)": 68.0,
      "(5, 1)": 67.0,
      "(3, 1)": 53.0,
      "(7, 0)": 63.0,
      "(0, 1)": 57.0,
      "(6, 0)": 202.0
    },
    "returns_count": {
      "(0, 0)": 65,
      "(1, 0)": 801,
      "(2, 0)": 698,
      "(3, 0)": 581,
      "(4, 0)": 442,
      "(1, 1)": 64,
      "(5, 0)": 324,
      "(4, 1)": 67,
      "(2, 1)": 75,
      "(7, 1)": 66,
      "(6, 1)": 68,
      "(5, 1)": 67,
      "(3, 1)": 53,
      "(7, 0)": 63,
      "(0, 1)": 57,
      "(6, 0)": 202
    }
  },
  "resultats_eval": {
    "avg_reward": -4.0,
    "min_reward": -4.0,
    "max_reward": -4.0,
    "execution_time": 0.0002913475036621094,
    "learning_curve": [
      0.0625,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0
    ],
    "rewards": [
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0,
      -4.0
    ],
    "steps_per_episode": [
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4,
      4
    ]
  },
  "score": -4.0,
  "reward_final": null,
  "eval_metrics": {
    "avg_reward": -4.0,
    "min_reward": -4.0,
    "max_reward": -4.0,
    "iterations": null,
    "execution_time": 0.0002913475036621094,
    "learning_curve": [
      0.0625,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0,
      1.0
    ]
  }
}
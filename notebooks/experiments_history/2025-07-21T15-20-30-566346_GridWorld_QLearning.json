{
  "datetime": "2025-07-21T15:20:30.566346",
  "environnement": "GridWorld",
  "modele": "QLearning",
  "hyperparametres": {
    "gamma": 0.99,
    "alpha": 0.1,
    "epsilon": 0.1,
    "num_episodes": 500
  },
  "resultats_train": {
    "Q": [
      [
        0.0,
        0.0,
        0.0,
        0.0
      ],
      [
        7.4581341716709995,
        0.0,
        0.0,
        0.0
      ],
      [
        3.617931257027,
        -0.010000000000000002,
        -0.05,
        0.012190152982571006
      ],
      [
        0.0767256443,
        -0.019000000000000003,
        -0.05,
        -0.010000000000000002
      ],
      [
        -0.019990000000000004,
        -0.05,
        -0.05,
        -0.019990000000000004
      ],
      [
        -0.05,
        -0.010000000000000002,
        7.4581341716709995,
        -0.010000000000000002
      ],
      [
        -0.019000000000000003,
        -0.010990000000000002,
        0.1691,
        -0.020088010000000003
      ],
      [
        -0.028090000000000004,
        -0.019990000000000004,
        1.179360944405335,
        -0.10099000000000001
      ],
      [
        -0.020881000000000004,
        -0.020881000000000004,
        -0.019990000000000004,
        3.8428948239715246
      ],
      [
        0.2232683873755017,
        -0.05,
        -0.020881000000000004,
        6.169974908694787
      ],
      [
        -0.05,
        -0.010990000000000002,
        3.6741033537271104,
        -0.019990000000000004
      ],
      [
        1.1936208117022606,
        -0.19099000000000002,
        -0.028981000000000007,
        -0.021772000000000003
      ],
      [
        0.19792276137154505,
        9.405979999999971,
        0.1820661957753676,
        0.7120690193253826
      ],
      [
        4.5306862111966835,
        9.601999999999979,
        0.4972667869454185,
        3.3982811999756843
      ],
      [
        5.3462800271162445,
        4.2634762723598865,
        2.68284346207034,
        9.799999999999986
      ],
      [
        -0.05,
        -0.029079010000000002,
        -0.003231100000000004,
        -0.019990000000000004
      ],
      [
        -0.03726001,
        -0.030771910000000006,
        -0.019990000000000004,
        -0.019990000000000004
      ],
      [
        -0.03726001,
        3.578129593588663,
        -0.1,
        -0.029872000000000006
      ],
      [
        -0.020979010000000003,
        8.992745895494153,
        -0.019990000000000004,
        -0.019000000000000003
      ],
      [
        3.83437271464334,
        5.735932527851706,
        5.4045701182254,
        9.999999999999993
      ],
      [
        -0.05,
        -0.019990000000000004,
        -0.020881000000000004,
        -0.05
      ],
      [
        -0.019990000000000004,
        -0.019990000000000004,
        -0.019990000000000004,
        -0.05
      ],
      [
        -0.019990000000000004,
        0.0719,
        -0.019990000000000004,
        -0.05
      ],
      [
        -0.019990000000000004,
        1.9,
        -0.010000000000000002,
        -0.05
      ],
      [
        0.0,
        0.0,
        0.0,
        0.0
      ]
    ],
    "policy": [
      0,
      0,
      0,
      0,
      0,
      2,
      2,
      2,
      3,
      3,
      2,
      0,
      1,
      1,
      3,
      2,
      2,
      1,
      1,
      3,
      1,
      0,
      1,
      1,
      0
    ],
    "history": [
      {
        "episode": 1,
        "reward": 4.000000000000002,
        "loss": 2.478048780487805,
        "steps": 41,
        "epsilon": 0.09982
      },
      {
        "episode": 2,
        "reward": 1.0000000000000053,
        "loss": 2.7804829489473684,
        "steps": 38,
        "epsilon": 0.09964
      },
      {
        "episode": 3,
        "reward": 7.8,
        "loss": 5.284968470526316,
        "steps": 19,
        "epsilon": 0.09946
      },
      {
        "episode": 4,
        "reward": 8.5,
        "loss": 12.5683398775,
        "steps": 8,
        "epsilon": 0.09928000000000001
      },
      {
        "episode": 5,
        "reward": 9.2,
        "loss": 16.411692562,
        "steps": 5,
        "epsilon": 0.09910000000000001
      },
      {
        "episode": 6,
        "reward": 9.3,
        "loss": 10.2334935303,
        "steps": 8,
        "epsilon": 0.09892000000000001
      },
      {
        "episode": 7,
        "reward": 8.1,
        "loss": 6.8640334873416675,
        "steps": 12,
        "epsilon": 0.09874000000000001
      },
      {
        "episode": 8,
        "reward": 9.7,
        "loss": 17.127605190314004,
        "steps": 4,
        "epsilon": 0.09856000000000001
      },
      {
        "episode": 9,
        "reward": 9.5,
        "loss": 13.64404488854427,
        "steps": 6,
        "epsilon": 0.09838000000000001
      },
      {
        "episode": 10,
        "reward": 8.7,
        "loss": 4.19425595723999,
        "steps": 14,
        "epsilon": 0.09820000000000001
      },
      {
        "episode": 11,
        "reward": 9.7,
        "loss": 17.11985386416525,
        "steps": 4,
        "epsilon": 0.09802000000000001
      },
      {
        "episode": 12,
        "reward": 9.7,
        "loss": 17.208218334155042,
        "steps": 4,
        "epsilon": 0.09784000000000001
      },
      {
        "episode": 13,
        "reward": 9.5,
        "loss": 9.8984881029735,
        "steps": 6,
        "epsilon": 0.09766000000000001
      },
      {
        "episode": 14,
        "reward": 9.7,
        "loss": 14.645288281527732,
        "steps": 4,
        "epsilon": 0.09748000000000001
      },
      {
        "episode": 15,
        "reward": 9.7,
        "loss": 13.511994323714665,
        "steps": 4,
        "epsilon": 0.09730000000000001
      },
      {
        "episode": 16,
        "reward": 9.7,
        "loss": 12.978721651536572,
        "steps": 4,
        "epsilon": 0.09712000000000001
      },
      {
        "episode": 17,
        "reward": 9.7,
        "loss": 12.792681367335826,
        "steps": 4,
        "epsilon": 0.09694000000000001
      },
      {
        "episode": 18,
        "reward": 9.3,
        "loss": 5.8935684905276,
        "steps": 8,
        "epsilon": 0.09676000000000001
      },
      {
        "episode": 19,
        "reward": 9.7,
        "loss": 11.525053311663278,
        "steps": 4,
        "epsilon": 0.09658000000000001
      },
      {
        "episode": 20,
        "reward": 9.7,
        "loss": 10.293725934050094,
        "steps": 4,
        "epsilon": 0.09640000000000001
      },
      {
        "episode": 21,
        "reward": 9.7,
        "loss": 9.46292175623806,
        "steps": 4,
        "epsilon": 0.09622000000000001
      },
      {
        "episode": 22,
        "reward": 9.7,
        "loss": 11.36081492379215,
        "steps": 4,
        "epsilon": 0.09604000000000001
      },
      {
        "episode": 23,
        "reward": 9.7,
        "loss": 8.773491596545574,
        "steps": 4,
        "epsilon": 0.09586000000000001
      },
      {
        "episode": 24,
        "reward": 9.7,
        "loss": 11.539590747014541,
        "steps": 4,
        "epsilon": 0.09568000000000002
      },
      {
        "episode": 25,
        "reward": 9.7,
        "loss": 8.194025680274658,
        "steps": 4,
        "epsilon": 0.09550000000000002
      },
      {
        "episode": 26,
        "reward": 9.7,
        "loss": 7.700881095391658,
        "steps": 4,
        "epsilon": 0.09532000000000002
      },
      {
        "episode": 27,
        "reward": 9.7,
        "loss": 7.2759838474537615,
        "steps": 4,
        "epsilon": 0.09514000000000002
      },
      {
        "episode": 28,
        "reward": 9.3,
        "loss": 5.942428898615861,
        "steps": 8,
        "epsilon": 0.09496000000000002
      },
      {
        "episode": 29,
        "reward": 9.7,
        "loss": 6.717830862489995,
        "steps": 4,
        "epsilon": 0.09478000000000002
      },
      {
        "episode": 30,
        "reward": 9.7,
        "loss": 6.39025939987958,
        "steps": 4,
        "epsilon": 0.09460000000000002
      },
      {
        "episode": 31,
        "reward": 9.7,
        "loss": 6.098978855856705,
        "steps": 4,
        "epsilon": 0.09442000000000002
      },
      {
        "episode": 32,
        "reward": 9.7,
        "loss": 5.835944406297017,
        "steps": 4,
        "epsilon": 0.09424000000000002
      },
      {
        "episode": 33,
        "reward": 9.7,
        "loss": 5.594754028796118,
        "steps": 4,
        "epsilon": 0.09406000000000002
      },
      {
        "episode": 34,
        "reward": 9.7,
        "loss": 5.3702839191003555,
        "steps": 4,
        "epsilon": 0.09388000000000002
      },
      {
        "episode": 35,
        "reward": 9.7,
        "loss": 5.158430901405372,
        "steps": 4,
        "epsilon": 0.09370000000000002
      },
      {
        "episode": 36,
        "reward": 9.7,
        "loss": 4.955927607240499,
        "steps": 4,
        "epsilon": 0.09352000000000002
      },
      {
        "episode": 37,
        "reward": 9.7,
        "loss": 4.760206005179478,
        "steps": 4,
        "epsilon": 0.09334000000000002
      },
      {
        "episode": 38,
        "reward": 9.7,
        "loss": 4.569292300035566,
        "steps": 4,
        "epsilon": 0.09316000000000002
      },
      {
        "episode": 39,
        "reward": 9.7,
        "loss": 4.381721766714644,
        "steps": 4,
        "epsilon": 0.09298000000000002
      },
      {
        "episode": 40,
        "reward": 9.7,
        "loss": 4.196466134936777,
        "steps": 4,
        "epsilon": 0.09280000000000002
      },
      {
        "episode": 41,
        "reward": 9.7,
        "loss": 4.012869022719,
        "steps": 4,
        "epsilon": 0.09262000000000002
      },
      {
        "episode": 42,
        "reward": 9.7,
        "loss": 3.830586898303573,
        "steps": 4,
        "epsilon": 0.09244000000000002
      },
      {
        "episode": 43,
        "reward": 9.7,
        "loss": 3.649534353094352,
        "steps": 4,
        "epsilon": 0.09226000000000002
      },
      {
        "episode": 44,
        "reward": 9.2,
        "loss": 18.553445843588353,
        "steps": 5,
        "epsilon": 0.09208000000000002
      },
      {
        "episode": 45,
        "reward": 9.7,
        "loss": 3.291765926252613,
        "steps": 4,
        "epsilon": 0.09190000000000002
      },
      {
        "episode": 46,
        "reward": 9.5,
        "loss": 14.577881524526092,
        "steps": 6,
        "epsilon": 0.09172000000000002
      },
      {
        "episode": 47,
        "reward": 9.7,
        "loss": 2.9422114605133602,
        "steps": 4,
        "epsilon": 0.09154000000000002
      },
      {
        "episode": 48,
        "reward": 9.7,
        "loss": 2.7717285085328864,
        "steps": 4,
        "epsilon": 0.09136000000000002
      },
      {
        "episode": 49,
        "reward": 9.3,
        "loss": 17.829663149799,
        "steps": 8,
        "epsilon": 0.09118000000000002
      },
      {
        "episode": 50,
        "reward": 9.7,
        "loss": 2.495644288046636,
        "steps": 4,
        "epsilon": 0.09100000000000003
      },
      {
        "episode": 51,
        "reward": 9.7,
        "loss": 2.3428088983592885,
        "steps": 4,
        "epsilon": 0.09082000000000003
      },
      {
        "episode": 52,
        "reward": 9.7,
        "loss": 2.1939811578992683,
        "steps": 4,
        "epsilon": 0.09064000000000003
      },
      {
        "episode": 53,
        "reward": 9.7,
        "loss": 2.049275766860129,
        "steps": 4,
        "epsilon": 0.09046000000000003
      },
      {
        "episode": 54,
        "reward": 9.7,
        "loss": 1.9089783853577786,
        "steps": 4,
        "epsilon": 0.09028000000000003
      },
      {
        "episode": 55,
        "reward": 9.2,
        "loss": 15.483338484225374,
        "steps": 5,
        "epsilon": 0.09010000000000003
      },
      {
        "episode": 56,
        "reward": 9.7,
        "loss": 1.6430770297480344,
        "steps": 4,
        "epsilon": 0.08992000000000003
      },
      {
        "episode": 57,
        "reward": 9.7,
        "loss": 1.5182014099043923,
        "steps": 4,
        "epsilon": 0.08974000000000003
      },
      {
        "episode": 58,
        "reward": 9.7,
        "loss": 1.3991223884135155,
        "steps": 4,
        "epsilon": 0.08956000000000003
      },
      {
        "episode": 59,
        "reward": 9.7,
        "loss": 1.2860682877575769,
        "steps": 4,
        "epsilon": 0.08938000000000003
      },
      {
        "episode": 60,
        "reward": 9.7,
        "loss": 1.1791933322076693,
        "steps": 4,
        "epsilon": 0.08920000000000003
      },
      {
        "episode": 61,
        "reward": 9.5,
        "loss": 12.322903564910513,
        "steps": 6,
        "epsilon": 0.08902000000000003
      },
      {
        "episode": 62,
        "reward": 9.7,
        "loss": 0.9842304192041503,
        "steps": 4,
        "epsilon": 0.08884000000000003
      },
      {
        "episode": 63,
        "reward": 9.7,
        "loss": 0.8960974057980347,
        "steps": 4,
        "epsilon": 0.08866000000000003
      },
      {
        "episode": 64,
        "reward": 9.7,
        "loss": 0.8140673591466011,
        "steps": 4,
        "epsilon": 0.08848000000000003
      },
      {
        "episode": 65,
        "reward": 9.7,
        "loss": 0.7379809680202596,
        "steps": 4,
        "epsilon": 0.08830000000000003
      },
      {
        "episode": 66,
        "reward": 9.7,
        "loss": 0.6676391449901302,
        "steps": 4,
        "epsilon": 0.08812000000000003
      },
      {
        "episode": 67,
        "reward": 9.7,
        "loss": 0.602811156707364,
        "steps": 4,
        "epsilon": 0.08794000000000003
      },
      {
        "episode": 68,
        "reward": 9.7,
        "loss": 0.5432422241699333,
        "steps": 4,
        "epsilon": 0.08776000000000003
      },
      {
        "episode": 69,
        "reward": 9.7,
        "loss": 0.4886604418161816,
        "steps": 4,
        "epsilon": 0.08758000000000003
      },
      {
        "episode": 70,
        "reward": 9.7,
        "loss": 0.43878293596880974,
        "steps": 4,
        "epsilon": 0.08740000000000003
      },
      {
        "episode": 71,
        "reward": 9.7,
        "loss": 0.3933212352289007,
        "steps": 4,
        "epsilon": 0.08722000000000003
      },
      {
        "episode": 72,
        "reward": 8.6,
        "loss": 8.039617231609373,
        "steps": 6,
        "epsilon": 0.08704000000000003
      },
      {
        "episode": 73,
        "reward": 9.7,
        "loss": 0.26955859444036634,
        "steps": 4,
        "epsilon": 0.08686000000000003
      },
      {
        "episode": 74,
        "reward": 9.7,
        "loss": 17.454228542241587,
        "steps": 4,
        "epsilon": 0.08668000000000003
      },
      {
        "episode": 75,
        "reward": 8.6,
        "loss": 7.141815253247686,
        "steps": 6,
        "epsilon": 0.08650000000000004
      },
      {
        "episode": 76,
        "reward": 9.7,
        "loss": 0.1621776994939025,
        "steps": 4,
        "epsilon": 0.08632000000000004
      },
      {
        "episode": 77,
        "reward": 9.7,
        "loss": 0.14703001268333843,
        "steps": 4,
        "epsilon": 0.08614000000000004
      },
      {
        "episode": 78,
        "reward": 9.7,
        "loss": 14.82864389601614,
        "steps": 4,
        "epsilon": 0.08596000000000004
      },
      {
        "episode": 79,
        "reward": 9.7,
        "loss": 0.11467385164658749,
        "steps": 4,
        "epsilon": 0.08578000000000004
      },
      {
        "episode": 80,
        "reward": 9.7,
        "loss": 0.10416829975989127,
        "steps": 4,
        "epsilon": 0.08560000000000004
      },
      {
        "episode": 81,
        "reward": 9.7,
        "loss": 0.09438441825238637,
        "steps": 4,
        "epsilon": 0.08542000000000004
      },
      {
        "episode": 82,
        "reward": 9.7,
        "loss": 0.08530953159503321,
        "steps": 4,
        "epsilon": 0.08524000000000004
      },
      {
        "episode": 83,
        "reward": 9.7,
        "loss": 9.549138543091107,
        "steps": 4,
        "epsilon": 0.08506000000000004
      },
      {
        "episode": 84,
        "reward": 9.7,
        "loss": 0.07692482771080271,
        "steps": 4,
        "epsilon": 0.08488000000000004
      },
      {
        "episode": 85,
        "reward": 9.7,
        "loss": 0.06920636459516169,
        "steps": 4,
        "epsilon": 0.08470000000000004
      },
      {
        "episode": 86,
        "reward": 9.7,
        "loss": 0.062126097007057235,
        "steps": 4,
        "epsilon": 0.08452000000000004
      },
      {
        "episode": 87,
        "reward": 9.7,
        "loss": 0.055652866864824235,
        "steps": 4,
        "epsilon": 0.08434000000000004
      },
      {
        "episode": 88,
        "reward": 9.7,
        "loss": 0.04975332113537911,
        "steps": 4,
        "epsilon": 0.08416000000000004
      },
      {
        "episode": 89,
        "reward": 9.7,
        "loss": 0.04439273598484721,
        "steps": 4,
        "epsilon": 0.08398000000000004
      },
      {
        "episode": 90,
        "reward": 9.7,
        "loss": 0.03953573688321192,
        "steps": 4,
        "epsilon": 0.08380000000000004
      },
      {
        "episode": 91,
        "reward": 9.7,
        "loss": 0.03514691212972521,
        "steps": 4,
        "epsilon": 0.08362000000000004
      },
      {
        "episode": 92,
        "reward": 9.7,
        "loss": 0.031191322617387364,
        "steps": 4,
        "epsilon": 0.08344000000000004
      },
      {
        "episode": 93,
        "reward": 9.7,
        "loss": 0.027634914165291534,
        "steps": 4,
        "epsilon": 0.08326000000000004
      },
      {
        "episode": 94,
        "reward": 9.7,
        "loss": 0.02444484087851511,
        "steps": 4,
        "epsilon": 0.08308000000000004
      },
      {
        "episode": 95,
        "reward": 9.5,
        "loss": 14.384535607161537,
        "steps": 6,
        "epsilon": 0.08290000000000004
      },
      {
        "episode": 96,
        "reward": 9.7,
        "loss": 10.242238262524882,
        "steps": 4,
        "epsilon": 0.08272000000000004
      },
      {
        "episode": 97,
        "reward": 9.7,
        "loss": 0.019842914405579292,
        "steps": 4,
        "epsilon": 0.08254000000000004
      },
      {
        "episode": 98,
        "reward": 9.7,
        "loss": 0.01732806028863821,
        "steps": 4,
        "epsilon": 0.08236000000000004
      },
      {
        "episode": 99,
        "reward": 9.7,
        "loss": 0.015119481557292612,
        "steps": 4,
        "epsilon": 0.08218000000000004
      },
      {
        "episode": 100,
        "reward": 9.7,
        "loss": 0.013181688367406954,
        "steps": 4,
        "epsilon": 0.08200000000000005
      },
      {
        "episode": 101,
        "reward": 9.7,
        "loss": 0.011483049028792174,
        "steps": 4,
        "epsilon": 0.08182000000000005
      },
      {
        "episode": 102,
        "reward": 9.7,
        "loss": 9.35286495801375,
        "steps": 4,
        "epsilon": 0.08164000000000005
      },
      {
        "episode": 103,
        "reward": 9.7,
        "loss": 0.009995404444691533,
        "steps": 4,
        "epsilon": 0.08146000000000005
      },
      {
        "episode": 104,
        "reward": 9.7,
        "loss": 0.008693716983539723,
        "steps": 4,
        "epsilon": 0.08128000000000005
      },
      {
        "episode": 105,
        "reward": 8.6,
        "loss": 7.891103288284426,
        "steps": 6,
        "epsilon": 0.08110000000000005
      },
      {
        "episode": 106,
        "reward": 9.7,
        "loss": 0.005480950402870932,
        "steps": 4,
        "epsilon": 0.08092000000000005
      },
      {
        "episode": 107,
        "reward": 9.7,
        "loss": 0.004785426511470628,
        "steps": 4,
        "epsilon": 0.08074000000000005
      },
      {
        "episode": 108,
        "reward": 9.7,
        "loss": 0.004173987194951453,
        "steps": 4,
        "epsilon": 0.08056000000000005
      },
      {
        "episode": 109,
        "reward": 9.7,
        "loss": 0.0036371275813888142,
        "steps": 4,
        "epsilon": 0.08038000000000005
      },
      {
        "episode": 110,
        "reward": 9.7,
        "loss": 0.003166312649055258,
        "steps": 4,
        "epsilon": 0.08020000000000005
      },
      {
        "episode": 111,
        "reward": 9.7,
        "loss": 0.002753895033363772,
        "steps": 4,
        "epsilon": 0.08002000000000005
      },
      {
        "episode": 112,
        "reward": 9.7,
        "loss": 0.002393036998661184,
        "steps": 4,
        "epsilon": 0.07984000000000005
      },
      {
        "episode": 113,
        "reward": 9.7,
        "loss": 0.0020776368930705198,
        "steps": 4,
        "epsilon": 0.07966000000000005
      },
      {
        "episode": 114,
        "reward": 9.7,
        "loss": 8.633288895466352,
        "steps": 4,
        "epsilon": 0.07948000000000005
      },
      {
        "episode": 115,
        "reward": 9.5,
        "loss": 12.820187842739246,
        "steps": 6,
        "epsilon": 0.07930000000000005
      },
      {
        "episode": 116,
        "reward": 9.7,
        "loss": 0.0015667083556124596,
        "steps": 4,
        "epsilon": 0.07912000000000005
      },
      {
        "episode": 117,
        "reward": 9.7,
        "loss": 0.001357731664324644,
        "steps": 4,
        "epsilon": 0.07894000000000005
      },
      {
        "episode": 118,
        "reward": 9.7,
        "loss": 0.001175502714404834,
        "steps": 4,
        "epsilon": 0.07876000000000005
      },
      {
        "episode": 119,
        "reward": 9.7,
        "loss": 0.0010167896359330388,
        "steps": 4,
        "epsilon": 0.07858000000000005
      },
      {
        "episode": 120,
        "reward": 9.3,
        "loss": 14.818728273276463,
        "steps": 8,
        "epsilon": 0.07840000000000005
      },
      {
        "episode": 121,
        "reward": 9.7,
        "loss": 0.0007587373275598136,
        "steps": 4,
        "epsilon": 0.07822000000000005
      },
      {
        "episode": 122,
        "reward": 9.5,
        "loss": 6.154138722725009,
        "steps": 6,
        "epsilon": 0.07804000000000005
      },
      {
        "episode": 123,
        "reward": 9.7,
        "loss": 0.0006545890253345926,
        "steps": 4,
        "epsilon": 0.07786000000000005
      },
      {
        "episode": 124,
        "reward": 9.2,
        "loss": 14.48998547145409,
        "steps": 5,
        "epsilon": 0.07768000000000005
      },
      {
        "episode": 125,
        "reward": 9.7,
        "loss": 0.0004860422712858902,
        "steps": 4,
        "epsilon": 0.07750000000000005
      },
      {
        "episode": 126,
        "reward": 9.7,
        "loss": 0.00041833394852012346,
        "steps": 4,
        "epsilon": 0.07732000000000006
      },
      {
        "episode": 127,
        "reward": 9.7,
        "loss": 8.133693336004693,
        "steps": 4,
        "epsilon": 0.07714000000000006
      },
      {
        "episode": 128,
        "reward": 9.7,
        "loss": 0.0003597904543602871,
        "steps": 4,
        "epsilon": 0.07696000000000006
      },
      {
        "episode": 129,
        "reward": 9.7,
        "loss": 0.0003092167001451197,
        "steps": 4,
        "epsilon": 0.07678000000000006
      },
      {
        "episode": 130,
        "reward": 9.7,
        "loss": 0.000265565659880276,
        "steps": 4,
        "epsilon": 0.07660000000000006
      },
      {
        "episode": 131,
        "reward": 9.7,
        "loss": 0.00022792137399949797,
        "steps": 4,
        "epsilon": 0.07642000000000006
      },
      {
        "episode": 132,
        "reward": 9.7,
        "loss": 0.0001954836650175953,
        "steps": 4,
        "epsilon": 0.07624000000000006
      },
      {
        "episode": 133,
        "reward": 9.5,
        "loss": 7.795290737770322,
        "steps": 6,
        "epsilon": 0.07606000000000006
      },
      {
        "episode": 134,
        "reward": 9.7,
        "loss": 0.00014352543190972465,
        "steps": 4,
        "epsilon": 0.07588000000000006
      },
      {
        "episode": 135,
        "reward": 9.7,
        "loss": 0.000122867316361386,
        "steps": 4,
        "epsilon": 0.07570000000000006
      },
      {
        "episode": 136,
        "reward": 9.7,
        "loss": 0.00010511998188216362,
        "steps": 4,
        "epsilon": 0.07552000000000006
      },
      {
        "episode": 137,
        "reward": 9.7,
        "loss": 8.988394164203665e-05,
        "steps": 4,
        "epsilon": 0.07534000000000006
      },
      {
        "episode": 138,
        "reward": 9.0,
        "loss": 21.049722698816613,
        "steps": 7,
        "epsilon": 0.07516000000000006
      },
      {
        "episode": 139,
        "reward": 9.7,
        "loss": 6.560612205608808e-05,
        "steps": 4,
        "epsilon": 0.07498000000000006
      },
      {
        "episode": 140,
        "reward": 9.7,
        "loss": 5.600432740641099e-05,
        "steps": 4,
        "epsilon": 0.07480000000000006
      },
      {
        "episode": 141,
        "reward": 9.7,
        "loss": 4.778266192315806e-05,
        "steps": 4,
        "epsilon": 0.07462000000000006
      },
      {
        "episode": 142,
        "reward": 9.7,
        "loss": 11.104662165604774,
        "steps": 4,
        "epsilon": 0.07444000000000006
      },
      {
        "episode": 143,
        "reward": 9.7,
        "loss": 3.3435318639468375e-05,
        "steps": 4,
        "epsilon": 0.07426000000000006
      },
      {
        "episode": 144,
        "reward": 9.7,
        "loss": 10.008755107245523,
        "steps": 4,
        "epsilon": 0.07408000000000006
      },
      {
        "episode": 145,
        "reward": 9.7,
        "loss": 2.3560641911680824e-05,
        "steps": 4,
        "epsilon": 0.07390000000000006
      },
      {
        "episode": 146,
        "reward": 9.7,
        "loss": 2.0279608447481577e-05,
        "steps": 4,
        "epsilon": 0.07372000000000006
      },
      {
        "episode": 147,
        "reward": 9.5,
        "loss": 10.39605484070526,
        "steps": 6,
        "epsilon": 0.07354000000000006
      },
      {
        "episode": 148,
        "reward": 9.5,
        "loss": 6.684334273934799,
        "steps": 6,
        "epsilon": 0.07336000000000006
      },
      {
        "episode": 149,
        "reward": 9.5,
        "loss": 12.000692564148133,
        "steps": 6,
        "epsilon": 0.07318000000000006
      },
      {
        "episode": 150,
        "reward": 9.7,
        "loss": 1.1480974456469668e-05,
        "steps": 4,
        "epsilon": 0.07300000000000006
      },
      {
        "episode": 151,
        "reward": 9.7,
        "loss": 9.785274945014605e-06,
        "steps": 4,
        "epsilon": 0.07282000000000007
      },
      {
        "episode": 152,
        "reward": 9.7,
        "loss": 8.335644813793242e-06,
        "steps": 4,
        "epsilon": 0.07264000000000007
      },
      {
        "episode": 153,
        "reward": 9.7,
        "loss": 7.0971277949957415e-06,
        "steps": 4,
        "epsilon": 0.07246000000000007
      },
      {
        "episode": 154,
        "reward": 9.7,
        "loss": 6.039604195053549e-06,
        "steps": 4,
        "epsilon": 0.07228000000000007
      },
      {
        "episode": 155,
        "reward": 9.7,
        "loss": 5.137144008257458e-06,
        "steps": 4,
        "epsilon": 0.07210000000000007
      },
      {
        "episode": 156,
        "reward": 9.5,
        "loss": 9.723154297985115,
        "steps": 6,
        "epsilon": 0.07192000000000007
      },
      {
        "episode": 157,
        "reward": 9.2,
        "loss": 13.988955413735743,
        "steps": 5,
        "epsilon": 0.07174000000000007
      },
      {
        "episode": 158,
        "reward": 8.6,
        "loss": 6.824602478439554,
        "steps": 6,
        "epsilon": 0.07156000000000007
      },
      {
        "episode": 159,
        "reward": 9.7,
        "loss": 2.246344144469457e-06,
        "steps": 4,
        "epsilon": 0.07138000000000007
      },
      {
        "episode": 160,
        "reward": 9.7,
        "loss": 1.9054315179074125e-06,
        "steps": 4,
        "epsilon": 0.07120000000000007
      },
      {
        "episode": 161,
        "reward": 9.7,
        "loss": 1.615686545763166e-06,
        "steps": 4,
        "epsilon": 0.07102000000000007
      },
      {
        "episode": 162,
        "reward": 9.7,
        "loss": 1.3695240055052805e-06,
        "steps": 4,
        "epsilon": 0.07084000000000007
      },
      {
        "episode": 163,
        "reward": 9.2,
        "loss": 11.33120636094064,
        "steps": 5,
        "epsilon": 0.07066000000000007
      },
      {
        "episode": 164,
        "reward": 9.7,
        "loss": 9.829901693068626e-07,
        "steps": 4,
        "epsilon": 0.07048000000000007
      },
      {
        "episode": 165,
        "reward": 9.7,
        "loss": 8.323771349000339e-07,
        "steps": 4,
        "epsilon": 0.07030000000000007
      },
      {
        "episode": 166,
        "reward": 9.5,
        "loss": 9.324859862430621,
        "steps": 6,
        "epsilon": 0.07012000000000007
      },
      {
        "episode": 167,
        "reward": 9.7,
        "loss": 5.962579983563695e-07,
        "steps": 4,
        "epsilon": 0.06994000000000007
      },
      {
        "episode": 168,
        "reward": 9.7,
        "loss": 5.044070298169902e-07,
        "steps": 4,
        "epsilon": 0.06976000000000007
      },
      {
        "episode": 169,
        "reward": 9.7,
        "loss": 4.2657013539719376e-07,
        "steps": 4,
        "epsilon": 0.06958000000000007
      },
      {
        "episode": 170,
        "reward": 8.6,
        "loss": 5.5329486068916856,
        "steps": 6,
        "epsilon": 0.06940000000000007
      },
      {
        "episode": 171,
        "reward": 9.7,
        "loss": 2.501928877982739e-07,
        "steps": 4,
        "epsilon": 0.06922000000000007
      },
      {
        "episode": 172,
        "reward": 9.7,
        "loss": 2.122899762940444e-07,
        "steps": 4,
        "epsilon": 0.06904000000000007
      },
      {
        "episode": 173,
        "reward": 9.7,
        "loss": 1.800527382579291e-07,
        "steps": 4,
        "epsilon": 0.06886000000000007
      },
      {
        "episode": 174,
        "reward": 9.7,
        "loss": 1.526473878793676e-07,
        "steps": 4,
        "epsilon": 0.06868000000000007
      },
      {
        "episode": 175,
        "reward": 9.7,
        "loss": 1.2936059480520643e-07,
        "steps": 4,
        "epsilon": 0.06850000000000007
      },
      {
        "episode": 176,
        "reward": 9.7,
        "loss": 1.0958246778901124e-07,
        "steps": 4,
        "epsilon": 0.06832000000000008
      },
      {
        "episode": 177,
        "reward": 9.7,
        "loss": 9.279187593723172e-08,
        "steps": 4,
        "epsilon": 0.06814000000000008
      },
      {
        "episode": 178,
        "reward": 9.7,
        "loss": 7.85437978370713e-08,
        "steps": 4,
        "epsilon": 0.06796000000000008
      },
      {
        "episode": 179,
        "reward": 9.7,
        "loss": 6.645842793619633e-08,
        "steps": 4,
        "epsilon": 0.06778000000000008
      },
      {
        "episode": 180,
        "reward": 9.7,
        "loss": 5.6211803987701635e-08,
        "steps": 4,
        "epsilon": 0.06760000000000008
      },
      {
        "episode": 181,
        "reward": 9.7,
        "loss": 4.752774974696355e-08,
        "steps": 4,
        "epsilon": 0.06742000000000008
      },
      {
        "episode": 182,
        "reward": 9.7,
        "loss": 4.0170953832392086e-08,
        "steps": 4,
        "epsilon": 0.06724000000000008
      },
      {
        "episode": 183,
        "reward": 9.7,
        "loss": 3.3941029077646027e-08,
        "steps": 4,
        "epsilon": 0.06706000000000008
      },
      {
        "episode": 184,
        "reward": 9.7,
        "loss": 2.866741725460298e-08,
        "steps": 4,
        "epsilon": 0.06688000000000008
      },
      {
        "episode": 185,
        "reward": 9.7,
        "loss": 2.4205022021200928e-08,
        "steps": 4,
        "epsilon": 0.06670000000000008
      },
      {
        "episode": 186,
        "reward": 9.7,
        "loss": 2.0430468615341747e-08,
        "steps": 4,
        "epsilon": 0.06652000000000008
      },
      {
        "episode": 187,
        "reward": 9.7,
        "loss": 1.7238902528572426e-08,
        "steps": 4,
        "epsilon": 0.06634000000000008
      },
      {
        "episode": 188,
        "reward": 9.5,
        "loss": 6.040042886374198,
        "steps": 6,
        "epsilon": 0.06616000000000008
      },
      {
        "episode": 189,
        "reward": 9.7,
        "loss": 1.2261883883213738e-08,
        "steps": 4,
        "epsilon": 0.06598000000000008
      },
      {
        "episode": 190,
        "reward": 9.7,
        "loss": 1.0336611250948807e-08,
        "steps": 4,
        "epsilon": 0.06580000000000008
      },
      {
        "episode": 191,
        "reward": 9.7,
        "loss": 8.710979298653288e-09,
        "steps": 4,
        "epsilon": 0.06562000000000008
      },
      {
        "episode": 192,
        "reward": 9.7,
        "loss": 7.3388123865244264e-09,
        "steps": 4,
        "epsilon": 0.06544000000000008
      },
      {
        "episode": 193,
        "reward": 9.7,
        "loss": 8.041086291368996,
        "steps": 4,
        "epsilon": 0.06526000000000008
      },
      {
        "episode": 194,
        "reward": 9.7,
        "loss": 7.62620514779158,
        "steps": 4,
        "epsilon": 0.06508000000000008
      },
      {
        "episode": 195,
        "reward": 9.7,
        "loss": 6.18097131650887e-09,
        "steps": 4,
        "epsilon": 0.06490000000000008
      },
      {
        "episode": 196,
        "reward": 9.7,
        "loss": 5.204294802690158e-09,
        "steps": 4,
        "epsilon": 0.06472000000000008
      },
      {
        "episode": 197,
        "reward": 9.7,
        "loss": 4.380697813500642e-09,
        "steps": 4,
        "epsilon": 0.06454000000000008
      },
      {
        "episode": 198,
        "reward": 9.5,
        "loss": 8.087497095076543,
        "steps": 6,
        "epsilon": 0.06436000000000008
      },
      {
        "episode": 199,
        "reward": 9.7,
        "loss": 3.1012922600670602e-09,
        "steps": 4,
        "epsilon": 0.06418000000000008
      },
      {
        "episode": 200,
        "reward": 9.5,
        "loss": 7.87787235788677,
        "steps": 6,
        "epsilon": 0.06400000000000008
      },
      {
        "episode": 201,
        "reward": 9.2,
        "loss": 9.178442299392145,
        "steps": 5,
        "epsilon": 0.06382000000000008
      },
      {
        "episode": 202,
        "reward": 9.7,
        "loss": 1.88686883316609e-09,
        "steps": 4,
        "epsilon": 0.06364000000000009
      },
      {
        "episode": 203,
        "reward": 9.7,
        "loss": 1.5795867667331457e-09,
        "steps": 4,
        "epsilon": 0.06346000000000009
      },
      {
        "episode": 204,
        "reward": 9.7,
        "loss": 1.3221765154627347e-09,
        "steps": 4,
        "epsilon": 0.06328000000000009
      },
      {
        "episode": 205,
        "reward": 9.7,
        "loss": 1.1065713303697836e-09,
        "steps": 4,
        "epsilon": 0.06310000000000009
      },
      {
        "episode": 206,
        "reward": 9.5,
        "loss": 7.119883594718497,
        "steps": 6,
        "epsilon": 0.06292000000000009
      },
      {
        "episode": 207,
        "reward": 9.5,
        "loss": 6.38109557207105,
        "steps": 6,
        "epsilon": 0.06274000000000009
      },
      {
        "episode": 208,
        "reward": 9.7,
        "loss": 6.641155038479155e-10,
        "steps": 4,
        "epsilon": 0.06256000000000009
      },
      {
        "episode": 209,
        "reward": 9.7,
        "loss": 5.536203088446098e-10,
        "steps": 4,
        "epsilon": 0.06238000000000009
      },
      {
        "episode": 210,
        "reward": 9.7,
        "loss": 4.614951293269508e-10,
        "steps": 4,
        "epsilon": 0.06220000000000009
      },
      {
        "episode": 211,
        "reward": 9.7,
        "loss": 3.846872614123194e-10,
        "steps": 4,
        "epsilon": 0.06202000000000009
      },
      {
        "episode": 212,
        "reward": 9.5,
        "loss": 8.421520003806785,
        "steps": 6,
        "epsilon": 0.06184000000000009
      },
      {
        "episode": 213,
        "reward": 9.7,
        "loss": 2.673582282577498e-10,
        "steps": 4,
        "epsilon": 0.06166000000000009
      },
      {
        "episode": 214,
        "reward": 9.7,
        "loss": 2.2289710619872903e-10,
        "steps": 4,
        "epsilon": 0.06148000000000009
      },
      {
        "episode": 215,
        "reward": 9.2,
        "loss": 9.507072472180967,
        "steps": 5,
        "epsilon": 0.06130000000000009
      },
      {
        "episode": 216,
        "reward": 9.7,
        "loss": 1.5488664979159842e-10,
        "steps": 4,
        "epsilon": 0.06112000000000009
      },
      {
        "episode": 217,
        "reward": 9.7,
        "loss": 1.29095857102112e-10,
        "steps": 4,
        "epsilon": 0.06094000000000009
      },
      {
        "episode": 218,
        "reward": 9.7,
        "loss": 1.0759021342434001e-10,
        "steps": 4,
        "epsilon": 0.06076000000000009
      },
      {
        "episode": 219,
        "reward": 9.7,
        "loss": 8.965927707869409e-11,
        "steps": 4,
        "epsilon": 0.06058000000000009
      },
      {
        "episode": 220,
        "reward": 9.7,
        "loss": 7.47101426268742e-11,
        "steps": 4,
        "epsilon": 0.06040000000000009
      },
      {
        "episode": 221,
        "reward": 9.0,
        "loss": 10.933406883388058,
        "steps": 7,
        "epsilon": 0.06022000000000009
      },
      {
        "episode": 222,
        "reward": 9.7,
        "loss": 5.186010328149143e-11,
        "steps": 4,
        "epsilon": 0.06004000000000009
      },
      {
        "episode": 223,
        "reward": 9.7,
        "loss": 12.477685940405447,
        "steps": 4,
        "epsilon": 0.059860000000000094
      },
      {
        "episode": 224,
        "reward": 9.7,
        "loss": 4.320194268974929e-11,
        "steps": 4,
        "epsilon": 0.059680000000000094
      },
      {
        "episode": 225,
        "reward": 9.7,
        "loss": 3.5986088815807894e-11,
        "steps": 4,
        "epsilon": 0.059500000000000094
      },
      {
        "episode": 226,
        "reward": 9.7,
        "loss": 2.997284153455696e-11,
        "steps": 4,
        "epsilon": 0.059320000000000095
      },
      {
        "episode": 227,
        "reward": 9.7,
        "loss": 2.4962204700439747e-11,
        "steps": 4,
        "epsilon": 0.059140000000000095
      },
      {
        "episode": 228,
        "reward": 9.7,
        "loss": 2.0787371802015873e-11,
        "steps": 4,
        "epsilon": 0.058960000000000096
      },
      {
        "episode": 229,
        "reward": 9.7,
        "loss": 1.7309229282413798e-11,
        "steps": 4,
        "epsilon": 0.058780000000000096
      },
      {
        "episode": 230,
        "reward": 9.5,
        "loss": 5.16870097303189,
        "steps": 6,
        "epsilon": 0.058600000000000096
      },
      {
        "episode": 231,
        "reward": 9.7,
        "loss": 1.2255712476340827e-11,
        "steps": 4,
        "epsilon": 0.0584200000000001
      },
      {
        "episode": 232,
        "reward": 9.7,
        "loss": 1.0172687117800252e-11,
        "steps": 4,
        "epsilon": 0.0582400000000001
      },
      {
        "episode": 233,
        "reward": 9.7,
        "loss": 9.584910756023383,
        "steps": 4,
        "epsilon": 0.0580600000000001
      },
      {
        "episode": 234,
        "reward": 9.7,
        "loss": 6.859260997332777e-12,
        "steps": 4,
        "epsilon": 0.0578800000000001
      },
      {
        "episode": 235,
        "reward": 9.7,
        "loss": 5.708332693221944e-12,
        "steps": 4,
        "epsilon": 0.0577000000000001
      },
      {
        "episode": 236,
        "reward": 9.5,
        "loss": 5.68619305314266,
        "steps": 6,
        "epsilon": 0.0575200000000001
      },
      {
        "episode": 237,
        "reward": 9.5,
        "loss": 13.808150068330034,
        "steps": 6,
        "epsilon": 0.0573400000000001
      },
      {
        "episode": 238,
        "reward": 9.7,
        "loss": 3.952734728315007e-12,
        "steps": 4,
        "epsilon": 0.0571600000000001
      },
      {
        "episode": 239,
        "reward": 9.7,
        "loss": 3.2889174993034597e-12,
        "steps": 4,
        "epsilon": 0.0569800000000001
      },
      {
        "episode": 240,
        "reward": 9.7,
        "loss": 10.927907267628397,
        "steps": 4,
        "epsilon": 0.0568000000000001
      },
      {
        "episode": 241,
        "reward": 9.7,
        "loss": 2.736417218805821e-12,
        "steps": 4,
        "epsilon": 0.0566200000000001
      },
      {
        "episode": 242,
        "reward": 9.7,
        "loss": 2.2765893367393474e-12,
        "steps": 4,
        "epsilon": 0.0564400000000001
      },
      {
        "episode": 243,
        "reward": 9.7,
        "loss": 1.8939126698380936e-12,
        "steps": 4,
        "epsilon": 0.0562600000000001
      },
      {
        "episode": 244,
        "reward": 9.7,
        "loss": 9.685347006883124,
        "steps": 4,
        "epsilon": 0.0560800000000001
      },
      {
        "episode": 245,
        "reward": 9.5,
        "loss": 5.797345467976662,
        "steps": 6,
        "epsilon": 0.0559000000000001
      },
      {
        "episode": 246,
        "reward": 9.7,
        "loss": 1.0682200019989325e-12,
        "steps": 4,
        "epsilon": 0.0557200000000001
      },
      {
        "episode": 247,
        "reward": 9.7,
        "loss": 8.909966890552133e-13,
        "steps": 4,
        "epsilon": 0.0555400000000001
      },
      {
        "episode": 248,
        "reward": 9.7,
        "loss": 7.430905415335121e-13,
        "steps": 4,
        "epsilon": 0.055360000000000104
      },
      {
        "episode": 249,
        "reward": 9.7,
        "loss": 6.19665762240873e-13,
        "steps": 4,
        "epsilon": 0.055180000000000104
      },
      {
        "episode": 250,
        "reward": 9.3,
        "loss": 14.19422178884958,
        "steps": 8,
        "epsilon": 0.055000000000000104
      },
      {
        "episode": 251,
        "reward": 9.7,
        "loss": 4.30890284573672e-13,
        "steps": 4,
        "epsilon": 0.054820000000000105
      },
      {
        "episode": 252,
        "reward": 9.7,
        "loss": 3.592768821423691e-13,
        "steps": 4,
        "epsilon": 0.054640000000000105
      },
      {
        "episode": 253,
        "reward": 9.7,
        "loss": 2.9952044930786145e-13,
        "steps": 4,
        "epsilon": 0.054460000000000106
      },
      {
        "episode": 254,
        "reward": 9.7,
        "loss": 2.496657039016073e-13,
        "steps": 4,
        "epsilon": 0.054280000000000106
      },
      {
        "episode": 255,
        "reward": 9.7,
        "loss": 2.0807843544738333e-13,
        "steps": 4,
        "epsilon": 0.054100000000000106
      },
      {
        "episode": 256,
        "reward": 9.7,
        "loss": 1.733930157860735e-13,
        "steps": 4,
        "epsilon": 0.05392000000000011
      },
      {
        "episode": 257,
        "reward": 9.5,
        "loss": 10.137205442225133,
        "steps": 6,
        "epsilon": 0.05374000000000011
      },
      {
        "episode": 258,
        "reward": 9.7,
        "loss": 1.203516112795457e-13,
        "steps": 4,
        "epsilon": 0.05356000000000011
      },
      {
        "episode": 259,
        "reward": 9.7,
        "loss": 1.0024640355776919e-13,
        "steps": 4,
        "epsilon": 0.05338000000000011
      },
      {
        "episode": 260,
        "reward": 9.7,
        "loss": 8.348803642776133e-14,
        "steps": 4,
        "epsilon": 0.05320000000000011
      },
      {
        "episode": 261,
        "reward": 9.7,
        "loss": 6.952144452031981e-14,
        "steps": 4,
        "epsilon": 0.05302000000000011
      },
      {
        "episode": 262,
        "reward": 9.7,
        "loss": 7.194724013633065,
        "steps": 4,
        "epsilon": 0.05284000000000011
      },
      {
        "episode": 263,
        "reward": 9.7,
        "loss": 7.545572875651941,
        "steps": 4,
        "epsilon": 0.05266000000000011
      },
      {
        "episode": 264,
        "reward": 9.7,
        "loss": 5.788325746105495e-14,
        "steps": 4,
        "epsilon": 0.05248000000000011
      },
      {
        "episode": 265,
        "reward": 9.7,
        "loss": 4.818671361604376e-14,
        "steps": 4,
        "epsilon": 0.05230000000000011
      },
      {
        "episode": 266,
        "reward": 9.7,
        "loss": 4.0109046977810586e-14,
        "steps": 4,
        "epsilon": 0.05212000000000011
      },
      {
        "episode": 267,
        "reward": 9.7,
        "loss": 3.338094310740592e-14,
        "steps": 4,
        "epsilon": 0.05194000000000011
      },
      {
        "episode": 268,
        "reward": 9.7,
        "loss": 2.7777720144802168e-14,
        "steps": 4,
        "epsilon": 0.05176000000000011
      },
      {
        "episode": 269,
        "reward": 9.7,
        "loss": 2.311196353398157e-14,
        "steps": 4,
        "epsilon": 0.05158000000000011
      },
      {
        "episode": 270,
        "reward": 9.7,
        "loss": 7.124225356498345,
        "steps": 4,
        "epsilon": 0.05140000000000011
      },
      {
        "episode": 271,
        "reward": 9.7,
        "loss": 1.9227368267382054e-14,
        "steps": 4,
        "epsilon": 0.05122000000000011
      },
      {
        "episode": 272,
        "reward": 9.7,
        "loss": 10.670268238285548,
        "steps": 4,
        "epsilon": 0.05104000000000011
      },
      {
        "episode": 273,
        "reward": 9.7,
        "loss": 1.5993602433472146e-14,
        "steps": 4,
        "epsilon": 0.05086000000000011
      },
      {
        "episode": 274,
        "reward": 9.7,
        "loss": 9.096349079172729,
        "steps": 4,
        "epsilon": 0.050680000000000114
      },
      {
        "episode": 275,
        "reward": 9.7,
        "loss": 1.0811338210108327e-14,
        "steps": 4,
        "epsilon": 0.050500000000000114
      },
      {
        "episode": 276,
        "reward": 9.7,
        "loss": 9.016236552838435e-15,
        "steps": 4,
        "epsilon": 0.050320000000000115
      },
      {
        "episode": 277,
        "reward": 9.7,
        "loss": 7.517836097052539e-15,
        "steps": 4,
        "epsilon": 0.050140000000000115
      },
      {
        "episode": 278,
        "reward": 9.7,
        "loss": 6.267338117904299e-15,
        "steps": 4,
        "epsilon": 0.049960000000000115
      },
      {
        "episode": 279,
        "reward": 9.7,
        "loss": 5.223926607981076e-15,
        "steps": 4,
        "epsilon": 0.049780000000000116
      },
      {
        "episode": 280,
        "reward": 9.5,
        "loss": 4.186649329252343,
        "steps": 6,
        "epsilon": 0.049600000000000116
      },
      {
        "episode": 281,
        "reward": 9.7,
        "loss": 3.7075062761066425e-15,
        "steps": 4,
        "epsilon": 0.04942000000000012
      },
      {
        "episode": 282,
        "reward": 9.7,
        "loss": 3.0794132740212345e-15,
        "steps": 4,
        "epsilon": 0.04924000000000012
      },
      {
        "episode": 283,
        "reward": 9.7,
        "loss": 6.82223008591309,
        "steps": 4,
        "epsilon": 0.04906000000000012
      },
      {
        "episode": 284,
        "reward": 9.7,
        "loss": 2.5574929830003866e-15,
        "steps": 4,
        "epsilon": 0.04888000000000012
      },
      {
        "episode": 285,
        "reward": 9.7,
        "loss": 2.123837833553334e-15,
        "steps": 4,
        "epsilon": 0.04870000000000012
      },
      {
        "episode": 286,
        "reward": 9.7,
        "loss": 1.7635536721462335e-15,
        "steps": 4,
        "epsilon": 0.04852000000000012
      },
      {
        "episode": 287,
        "reward": 9.7,
        "loss": 1.4642542471201245e-15,
        "steps": 4,
        "epsilon": 0.04834000000000012
      },
      {
        "episode": 288,
        "reward": 9.7,
        "loss": 1.2156394697816806e-15,
        "steps": 4,
        "epsilon": 0.04816000000000012
      },
      {
        "episode": 289,
        "reward": 9.7,
        "loss": 1.009145255258727e-15,
        "steps": 4,
        "epsilon": 0.04798000000000012
      },
      {
        "episode": 290,
        "reward": 9.7,
        "loss": 8.376510686683645e-16,
        "steps": 4,
        "epsilon": 0.04780000000000012
      },
      {
        "episode": 291,
        "reward": 9.7,
        "loss": 6.952377371239175e-16,
        "steps": 4,
        "epsilon": 0.04762000000000012
      },
      {
        "episode": 292,
        "reward": 8.6,
        "loss": 4.483950298347964,
        "steps": 6,
        "epsilon": 0.04744000000000012
      },
      {
        "episode": 293,
        "reward": 9.7,
        "loss": 3.899644252462395e-16,
        "steps": 4,
        "epsilon": 0.04726000000000012
      },
      {
        "episode": 294,
        "reward": 9.7,
        "loss": 3.244111384026654e-16,
        "steps": 4,
        "epsilon": 0.04708000000000012
      },
      {
        "episode": 295,
        "reward": 9.7,
        "loss": 2.6984153315792477e-16,
        "steps": 4,
        "epsilon": 0.04690000000000012
      },
      {
        "episode": 296,
        "reward": 9.7,
        "loss": 2.244215081954944e-16,
        "steps": 4,
        "epsilon": 0.04672000000000012
      },
      {
        "episode": 297,
        "reward": 9.7,
        "loss": 1.8662225444200185e-16,
        "steps": 4,
        "epsilon": 0.04654000000000012
      },
      {
        "episode": 298,
        "reward": 9.7,
        "loss": 1.551693432678017e-16,
        "steps": 4,
        "epsilon": 0.04636000000000012
      },
      {
        "episode": 299,
        "reward": 9.7,
        "loss": 1.2900084108529528e-16,
        "steps": 4,
        "epsilon": 0.046180000000000124
      },
      {
        "episode": 300,
        "reward": 9.7,
        "loss": 1.0723184276144589e-16,
        "steps": 4,
        "epsilon": 0.046000000000000124
      },
      {
        "episode": 301,
        "reward": 9.7,
        "loss": 8.9125097390303e-17,
        "steps": 4,
        "epsilon": 0.045820000000000125
      },
      {
        "episode": 302,
        "reward": 9.3,
        "loss": 7.988099513256536,
        "steps": 8,
        "epsilon": 0.045640000000000125
      },
      {
        "episode": 303,
        "reward": 9.7,
        "loss": 6.15554844138789e-17,
        "steps": 4,
        "epsilon": 0.045460000000000125
      },
      {
        "episode": 304,
        "reward": 9.7,
        "loss": 5.115022099637788e-17,
        "steps": 4,
        "epsilon": 0.045280000000000126
      },
      {
        "episode": 305,
        "reward": 9.7,
        "loss": 4.249765427821656e-17,
        "steps": 4,
        "epsilon": 0.045100000000000126
      },
      {
        "episode": 306,
        "reward": 9.7,
        "loss": 3.53036949188788e-17,
        "steps": 4,
        "epsilon": 0.044920000000000126
      },
      {
        "episode": 307,
        "reward": 9.7,
        "loss": 2.932335884455034e-17,
        "steps": 4,
        "epsilon": 0.04474000000000013
      },
      {
        "episode": 308,
        "reward": 9.7,
        "loss": 2.4352663105525297e-17,
        "steps": 4,
        "epsilon": 0.04456000000000013
      },
      {
        "episode": 309,
        "reward": 9.7,
        "loss": 2.022176824088972e-17,
        "steps": 4,
        "epsilon": 0.04438000000000013
      },
      {
        "episode": 310,
        "reward": 9.7,
        "loss": 1.6789296825590734e-17,
        "steps": 4,
        "epsilon": 0.04420000000000013
      },
      {
        "episode": 311,
        "reward": 9.7,
        "loss": 1.3937572302161208e-17,
        "steps": 4,
        "epsilon": 0.04402000000000013
      },
      {
        "episode": 312,
        "reward": 9.7,
        "loss": 1.1568685869722845e-17,
        "steps": 4,
        "epsilon": 0.04384000000000013
      },
      {
        "episode": 313,
        "reward": 9.7,
        "loss": 9.601157690519559e-18,
        "steps": 4,
        "epsilon": 0.04366000000000013
      },
      {
        "episode": 314,
        "reward": 9.7,
        "loss": 7.967220858100525e-18,
        "steps": 4,
        "epsilon": 0.04348000000000013
      },
      {
        "episode": 315,
        "reward": 9.7,
        "loss": 6.610499385530437e-18,
        "steps": 4,
        "epsilon": 0.04330000000000013
      },
      {
        "episode": 316,
        "reward": 9.7,
        "loss": 5.4841124259968514e-18,
        "steps": 4,
        "epsilon": 0.04312000000000013
      },
      {
        "episode": 317,
        "reward": 9.7,
        "loss": 4.549083870138795e-18,
        "steps": 4,
        "epsilon": 0.04294000000000013
      },
      {
        "episode": 318,
        "reward": 9.7,
        "loss": 3.773004485954481e-18,
        "steps": 4,
        "epsilon": 0.04276000000000013
      },
      {
        "episode": 319,
        "reward": 9.7,
        "loss": 3.1289444077696827e-18,
        "steps": 4,
        "epsilon": 0.04258000000000013
      },
      {
        "episode": 320,
        "reward": 9.7,
        "loss": 2.5945122810677138e-18,
        "steps": 4,
        "epsilon": 0.04240000000000013
      },
      {
        "episode": 321,
        "reward": 9.7,
        "loss": 2.151103433459547e-18,
        "steps": 4,
        "epsilon": 0.04222000000000013
      },
      {
        "episode": 322,
        "reward": 9.7,
        "loss": 9.957913914879695,
        "steps": 4,
        "epsilon": 0.04204000000000013
      },
      {
        "episode": 323,
        "reward": 9.7,
        "loss": 1.7832650080227205e-18,
        "steps": 4,
        "epsilon": 0.04186000000000013
      },
      {
        "episode": 324,
        "reward": 9.7,
        "loss": 1.478151915087361e-18,
        "steps": 4,
        "epsilon": 0.041680000000000134
      },
      {
        "episode": 325,
        "reward": 9.7,
        "loss": 1.2251026133426636e-18,
        "steps": 4,
        "epsilon": 0.041500000000000134
      },
      {
        "episode": 326,
        "reward": 9.7,
        "loss": 1.0152563953413414e-18,
        "steps": 4,
        "epsilon": 0.041320000000000134
      },
      {
        "episode": 327,
        "reward": 9.7,
        "loss": 8.412593272728305e-19,
        "steps": 4,
        "epsilon": 0.041140000000000135
      },
      {
        "episode": 328,
        "reward": 9.7,
        "loss": 6.970048488210576e-19,
        "steps": 4,
        "epsilon": 0.040960000000000135
      },
      {
        "episode": 329,
        "reward": 9.7,
        "loss": 5.774228470110101e-19,
        "steps": 4,
        "epsilon": 0.040780000000000136
      },
      {
        "episode": 330,
        "reward": 9.7,
        "loss": 4.783039262678825e-19,
        "steps": 4,
        "epsilon": 0.040600000000000136
      },
      {
        "episode": 331,
        "reward": 9.7,
        "loss": 3.961564898589449e-19,
        "steps": 4,
        "epsilon": 0.040420000000000136
      },
      {
        "episode": 332,
        "reward": 9.3,
        "loss": 8.291520367990797,
        "steps": 8,
        "epsilon": 0.04024000000000014
      },
      {
        "episode": 333,
        "reward": 9.7,
        "loss": 2.765232656750127e-19,
        "steps": 4,
        "epsilon": 0.04006000000000014
      },
      {
        "episode": 334,
        "reward": 9.7,
        "loss": 2.284265272219856e-19,
        "steps": 4,
        "epsilon": 0.03988000000000014
      },
      {
        "episode": 335,
        "reward": 9.7,
        "loss": 1.8868501756236027e-19,
        "steps": 4,
        "epsilon": 0.03970000000000014
      },
      {
        "episode": 336,
        "reward": 9.7,
        "loss": 1.5584848339710548e-19,
        "steps": 4,
        "epsilon": 0.03952000000000014
      },
      {
        "episode": 337,
        "reward": 9.7,
        "loss": 8.05025215680336,
        "steps": 4,
        "epsilon": 0.03934000000000014
      },
      {
        "episode": 338,
        "reward": 9.7,
        "loss": 1.0445421656263996e-19,
        "steps": 4,
        "epsilon": 0.03916000000000014
      },
      {
        "episode": 339,
        "reward": 9.7,
        "loss": 8.644948778888259e-20,
        "steps": 4,
        "epsilon": 0.03898000000000014
      },
      {
        "episode": 340,
        "reward": 9.7,
        "loss": 7.154128505652281e-20,
        "steps": 4,
        "epsilon": 0.03880000000000014
      },
      {
        "episode": 341,
        "reward": 9.7,
        "loss": 5.919954643139752e-20,
        "steps": 4,
        "epsilon": 0.03862000000000014
      },
      {
        "episode": 342,
        "reward": 9.7,
        "loss": 4.898262337178772e-20,
        "steps": 4,
        "epsilon": 0.03844000000000014
      },
      {
        "episode": 343,
        "reward": 9.7,
        "loss": 4.0525731239152836e-20,
        "steps": 4,
        "epsilon": 0.03826000000000014
      },
      {
        "episode": 344,
        "reward": 9.5,
        "loss": 5.797165475699469,
        "steps": 6,
        "epsilon": 0.03808000000000014
      },
      {
        "episode": 345,
        "reward": 9.7,
        "loss": 2.773294102781202e-20,
        "steps": 4,
        "epsilon": 0.03790000000000014
      },
      {
        "episode": 346,
        "reward": 9.7,
        "loss": 2.293893333838572e-20,
        "steps": 4,
        "epsilon": 0.03772000000000014
      },
      {
        "episode": 347,
        "reward": 9.7,
        "loss": 1.8972048434852648e-20,
        "steps": 4,
        "epsilon": 0.03754000000000014
      },
      {
        "episode": 348,
        "reward": 9.7,
        "loss": 1.5690198000473502e-20,
        "steps": 4,
        "epsilon": 0.03736000000000014
      },
      {
        "episode": 349,
        "reward": 9.7,
        "loss": 1.2974630067653349e-20,
        "steps": 4,
        "epsilon": 0.037180000000000143
      },
      {
        "episode": 350,
        "reward": 9.7,
        "loss": 1.0728349955067646e-20,
        "steps": 4,
        "epsilon": 0.037000000000000144
      },
      {
        "episode": 351,
        "reward": 9.7,
        "loss": 8.870299118681076e-21,
        "steps": 4,
        "epsilon": 0.036820000000000144
      },
      {
        "episode": 352,
        "reward": 9.7,
        "loss": 7.333495074531011e-21,
        "steps": 4,
        "epsilon": 0.036640000000000145
      },
      {
        "episode": 353,
        "reward": 9.7,
        "loss": 6.0624203795717664e-21,
        "steps": 4,
        "epsilon": 0.036460000000000145
      },
      {
        "episode": 354,
        "reward": 8.6,
        "loss": 3.631999816354791,
        "steps": 6,
        "epsilon": 0.036280000000000145
      },
      {
        "episode": 355,
        "reward": 9.7,
        "loss": 3.3691908481966968e-21,
        "steps": 4,
        "epsilon": 0.036100000000000146
      },
      {
        "episode": 356,
        "reward": 9.7,
        "loss": 2.7905933940812275e-21,
        "steps": 4,
        "epsilon": 0.035920000000000146
      },
      {
        "episode": 357,
        "reward": 8.6,
        "loss": 2.94191985130882,
        "steps": 6,
        "epsilon": 0.03574000000000015
      },
      {
        "episode": 358,
        "reward": 9.7,
        "loss": 1.5577369352757602e-21,
        "steps": 4,
        "epsilon": 0.03556000000000015
      },
      {
        "episode": 359,
        "reward": 9.7,
        "loss": 1.2928776539094663e-21,
        "steps": 4,
        "epsilon": 0.03538000000000015
      },
      {
        "episode": 360,
        "reward": 9.7,
        "loss": 1.0728777880554293e-21,
        "steps": 4,
        "epsilon": 0.03520000000000015
      },
      {
        "episode": 361,
        "reward": 9.7,
        "loss": 8.902282551649672e-22,
        "steps": 4,
        "epsilon": 0.03502000000000015
      },
      {
        "episode": 362,
        "reward": 9.7,
        "loss": 7.385595761414375e-22,
        "steps": 4,
        "epsilon": 0.03484000000000015
      },
      {
        "episode": 363,
        "reward": 9.7,
        "loss": 6.125943488372805e-22,
        "steps": 4,
        "epsilon": 0.03466000000000015
      },
      {
        "episode": 364,
        "reward": 9.2,
        "loss": 7.434542480860242,
        "steps": 5,
        "epsilon": 0.03448000000000015
      },
      {
        "episode": 365,
        "reward": 9.7,
        "loss": 4.2137245539412076e-22,
        "steps": 4,
        "epsilon": 0.03430000000000015
      },
      {
        "episode": 366,
        "reward": 9.7,
        "loss": 3.4936262162481143e-22,
        "steps": 4,
        "epsilon": 0.03412000000000015
      },
      {
        "episode": 367,
        "reward": 9.7,
        "loss": 2.8963747970765463e-22,
        "steps": 4,
        "epsilon": 0.03394000000000015
      },
      {
        "episode": 368,
        "reward": 9.7,
        "loss": 2.4009253807413796e-22,
        "steps": 4,
        "epsilon": 0.03376000000000015
      },
      {
        "episode": 369,
        "reward": 9.7,
        "loss": 1.989837664689198e-22,
        "steps": 4,
        "epsilon": 0.03358000000000015
      },
      {
        "episode": 370,
        "reward": 9.7,
        "loss": 1.6488592752795461e-22,
        "steps": 4,
        "epsilon": 0.03340000000000015
      },
      {
        "episode": 371,
        "reward": 9.5,
        "loss": 4.475541739677236,
        "steps": 6,
        "epsilon": 0.03322000000000015
      },
      {
        "episode": 372,
        "reward": 9.7,
        "loss": 1.1322085910278406e-22,
        "steps": 4,
        "epsilon": 0.03304000000000015
      },
      {
        "episode": 373,
        "reward": 9.7,
        "loss": 9.378806271901327e-23,
        "steps": 4,
        "epsilon": 0.03286000000000015
      },
      {
        "episode": 374,
        "reward": 9.7,
        "loss": 7.768912031617313e-23,
        "steps": 4,
        "epsilon": 0.03268000000000015
      },
      {
        "episode": 375,
        "reward": 9.7,
        "loss": 6.434815554484324e-23,
        "steps": 4,
        "epsilon": 0.032500000000000154
      },
      {
        "episode": 376,
        "reward": 9.7,
        "loss": 5.32877892282291e-23,
        "steps": 4,
        "epsilon": 0.032320000000000154
      },
      {
        "episode": 377,
        "reward": 9.7,
        "loss": 4.4121453490362555e-23,
        "steps": 4,
        "epsilon": 0.032140000000000155
      },
      {
        "episode": 378,
        "reward": 9.5,
        "loss": 3.625188809138661,
        "steps": 6,
        "epsilon": 0.031960000000000155
      },
      {
        "episode": 379,
        "reward": 9.7,
        "loss": 3.02520749748358e-23,
        "steps": 4,
        "epsilon": 0.031780000000000155
      },
      {
        "episode": 380,
        "reward": 9.7,
        "loss": 2.5043946647667926e-23,
        "steps": 4,
        "epsilon": 0.031600000000000156
      },
      {
        "episode": 381,
        "reward": 9.7,
        "loss": 2.0732701104916598e-23,
        "steps": 4,
        "epsilon": 0.031420000000000156
      },
      {
        "episode": 382,
        "reward": 9.7,
        "loss": 1.7153330733314926e-23,
        "steps": 4,
        "epsilon": 0.031240000000000157
      },
      {
        "episode": 383,
        "reward": 9.7,
        "loss": 1.419449176039549e-23,
        "steps": 4,
        "epsilon": 0.031060000000000157
      },
      {
        "episode": 384,
        "reward": 9.7,
        "loss": 1.1740974206394384e-23,
        "steps": 4,
        "epsilon": 0.030880000000000157
      },
      {
        "episode": 385,
        "reward": 9.7,
        "loss": 9.541341580787462,
        "steps": 4,
        "epsilon": 0.030700000000000158
      },
      {
        "episode": 386,
        "reward": 9.7,
        "loss": 9.713606413141815e-24,
        "steps": 4,
        "epsilon": 0.030520000000000158
      },
      {
        "episode": 387,
        "reward": 9.7,
        "loss": 8.034783400225761e-24,
        "steps": 4,
        "epsilon": 0.03034000000000016
      },
      {
        "episode": 388,
        "reward": 9.7,
        "loss": 6.638861685140067e-24,
        "steps": 4,
        "epsilon": 0.03016000000000016
      },
      {
        "episode": 389,
        "reward": 9.2,
        "loss": 6.2375902872858235,
        "steps": 5,
        "epsilon": 0.02998000000000016
      },
      {
        "episode": 390,
        "reward": 9.7,
        "loss": 4.5381724261908255e-24,
        "steps": 4,
        "epsilon": 0.02980000000000016
      },
      {
        "episode": 391,
        "reward": 9.0,
        "loss": 6.515622364598015,
        "steps": 7,
        "epsilon": 0.02962000000000016
      },
      {
        "episode": 392,
        "reward": 9.7,
        "loss": 3.148636540132895e-24,
        "steps": 4,
        "epsilon": 0.02944000000000016
      },
      {
        "episode": 393,
        "reward": 9.7,
        "loss": 2.5964694052189218e-24,
        "steps": 4,
        "epsilon": 0.02926000000000016
      },
      {
        "episode": 394,
        "reward": 9.7,
        "loss": 2.141521488264386e-24,
        "steps": 4,
        "epsilon": 0.02908000000000016
      },
      {
        "episode": 395,
        "reward": 9.7,
        "loss": 1.768014782303962e-24,
        "steps": 4,
        "epsilon": 0.02890000000000016
      },
      {
        "episode": 396,
        "reward": 9.3,
        "loss": 6.933886556098531,
        "steps": 8,
        "epsilon": 0.028720000000000162
      },
      {
        "episode": 397,
        "reward": 9.7,
        "loss": 1.201381516110046e-24,
        "steps": 4,
        "epsilon": 0.028540000000000162
      },
      {
        "episode": 398,
        "reward": 9.7,
        "loss": 9.906680908555563e-25,
        "steps": 4,
        "epsilon": 0.028360000000000163
      },
      {
        "episode": 399,
        "reward": 9.7,
        "loss": 8.147055661978626e-25,
        "steps": 4,
        "epsilon": 0.028180000000000163
      },
      {
        "episode": 400,
        "reward": 9.7,
        "loss": 6.719209534919542e-25,
        "steps": 4,
        "epsilon": 0.028000000000000164
      },
      {
        "episode": 401,
        "reward": 9.7,
        "loss": 5.534750662948298e-25,
        "steps": 4,
        "epsilon": 0.027820000000000164
      },
      {
        "episode": 402,
        "reward": 9.7,
        "loss": 4.560223455074468e-25,
        "steps": 4,
        "epsilon": 0.027640000000000164
      },
      {
        "episode": 403,
        "reward": 9.7,
        "loss": 3.756437301526675e-25,
        "steps": 4,
        "epsilon": 0.027460000000000165
      },
      {
        "episode": 404,
        "reward": 9.7,
        "loss": 3.0900628290593298e-25,
        "steps": 4,
        "epsilon": 0.027280000000000165
      },
      {
        "episode": 405,
        "reward": 9.7,
        "loss": 2.550939509213186e-25,
        "steps": 4,
        "epsilon": 0.027100000000000166
      },
      {
        "episode": 406,
        "reward": 9.7,
        "loss": 2.0963899670157867e-25,
        "steps": 4,
        "epsilon": 0.026920000000000166
      },
      {
        "episode": 407,
        "reward": 9.7,
        "loss": 1.7303348411660806e-25,
        "steps": 4,
        "epsilon": 0.026740000000000166
      },
      {
        "episode": 408,
        "reward": 9.7,
        "loss": 1.419831300262038e-25,
        "steps": 4,
        "epsilon": 0.026560000000000167
      },
      {
        "episode": 409,
        "reward": 9.2,
        "loss": 6.021979409497348,
        "steps": 5,
        "epsilon": 0.026380000000000167
      },
      {
        "episode": 410,
        "reward": 9.7,
        "loss": 9.664256063772094e-26,
        "steps": 4,
        "epsilon": 0.026200000000000168
      },
      {
        "episode": 411,
        "reward": 9.7,
        "loss": 7.971439447258324e-26,
        "steps": 4,
        "epsilon": 0.026020000000000168
      },
      {
        "episode": 412,
        "reward": 9.7,
        "loss": 6.535081511031906e-26,
        "steps": 4,
        "epsilon": 0.02584000000000017
      },
      {
        "episode": 413,
        "reward": 9.7,
        "loss": 5.363701952869226e-26,
        "steps": 4,
        "epsilon": 0.02566000000000017
      },
      {
        "episode": 414,
        "reward": 9.7,
        "loss": 4.418962132776542e-26,
        "steps": 4,
        "epsilon": 0.02548000000000017
      },
      {
        "episode": 415,
        "reward": 9.7,
        "loss": 3.6329411268143257e-26,
        "steps": 4,
        "epsilon": 0.02530000000000017
      },
      {
        "episode": 416,
        "reward": 9.7,
        "loss": 2.986942931528839e-26,
        "steps": 4,
        "epsilon": 0.02512000000000017
      },
      {
        "episode": 417,
        "reward": 9.7,
        "loss": 2.4594316442075485e-26,
        "steps": 4,
        "epsilon": 0.02494000000000017
      },
      {
        "episode": 418,
        "reward": 9.7,
        "loss": 2.0082032064211298e-26,
        "steps": 4,
        "epsilon": 0.02476000000000017
      },
      {
        "episode": 419,
        "reward": 9.7,
        "loss": 1.6478515449161716e-26,
        "steps": 4,
        "epsilon": 0.02458000000000017
      },
      {
        "episode": 420,
        "reward": 9.7,
        "loss": 1.3641771633986957e-26,
        "steps": 4,
        "epsilon": 0.02440000000000017
      },
      {
        "episode": 421,
        "reward": 9.7,
        "loss": 1.1260200561124723e-26,
        "steps": 4,
        "epsilon": 0.024220000000000172
      },
      {
        "episode": 422,
        "reward": 9.2,
        "loss": 4.0924829874882285,
        "steps": 5,
        "epsilon": 0.024040000000000172
      },
      {
        "episode": 423,
        "reward": 9.7,
        "loss": 7.6401178670655e-27,
        "steps": 4,
        "epsilon": 0.023860000000000173
      },
      {
        "episode": 424,
        "reward": 9.7,
        "loss": 6.302209771810663e-27,
        "steps": 4,
        "epsilon": 0.023680000000000173
      },
      {
        "episode": 425,
        "reward": 9.7,
        "loss": 5.220681470752656e-27,
        "steps": 4,
        "epsilon": 0.023500000000000174
      },
      {
        "episode": 426,
        "reward": 9.7,
        "loss": 4.357667640440869e-27,
        "steps": 4,
        "epsilon": 0.023320000000000174
      },
      {
        "episode": 427,
        "reward": 9.7,
        "loss": 3.5790619269877306e-27,
        "steps": 4,
        "epsilon": 0.023140000000000174
      },
      {
        "episode": 428,
        "reward": 9.7,
        "loss": 2.877764582246251e-27,
        "steps": 4,
        "epsilon": 0.022960000000000175
      },
      {
        "episode": 429,
        "reward": 9.7,
        "loss": 2.338183723075079e-27,
        "steps": 4,
        "epsilon": 0.022780000000000175
      },
      {
        "episode": 430,
        "reward": 9.7,
        "loss": 1.931920356886258e-27,
        "steps": 4,
        "epsilon": 0.022600000000000176
      },
      {
        "episode": 431,
        "reward": 9.7,
        "loss": 1.5651000359584874e-27,
        "steps": 4,
        "epsilon": 0.022420000000000176
      },
      {
        "episode": 432,
        "reward": 9.7,
        "loss": 1.3000427718042275e-27,
        "steps": 4,
        "epsilon": 0.022240000000000176
      },
      {
        "episode": 433,
        "reward": 9.7,
        "loss": 6.760236047655362,
        "steps": 4,
        "epsilon": 0.022060000000000177
      },
      {
        "episode": 434,
        "reward": 9.7,
        "loss": 1.0602290566170399e-27,
        "steps": 4,
        "epsilon": 0.021880000000000177
      },
      {
        "episode": 435,
        "reward": 9.7,
        "loss": 8.456588903969247e-28,
        "steps": 4,
        "epsilon": 0.021700000000000177
      },
      {
        "episode": 436,
        "reward": 9.7,
        "loss": 7.012973447414795e-28,
        "steps": 4,
        "epsilon": 0.021520000000000178
      },
      {
        "episode": 437,
        "reward": 9.7,
        "loss": 5.7113529538001255e-28,
        "steps": 4,
        "epsilon": 0.02134000000000018
      },
      {
        "episode": 438,
        "reward": 9.7,
        "loss": 4.551727423125238e-28,
        "steps": 4,
        "epsilon": 0.02116000000000018
      },
      {
        "episode": 439,
        "reward": 9.7,
        "loss": 3.8575298265307477e-28,
        "steps": 4,
        "epsilon": 0.02098000000000018
      },
      {
        "episode": 440,
        "reward": 9.7,
        "loss": 3.2264411023539383e-28,
        "steps": 4,
        "epsilon": 0.02080000000000018
      },
      {
        "episode": 441,
        "reward": 9.7,
        "loss": 2.65846125059481e-28,
        "steps": 4,
        "epsilon": 0.02062000000000018
      },
      {
        "episode": 442,
        "reward": 9.7,
        "loss": 2.1535902712533622e-28,
        "steps": 4,
        "epsilon": 0.02044000000000018
      },
      {
        "episode": 443,
        "reward": 9.7,
        "loss": 1.7118281643295956e-28,
        "steps": 4,
        "epsilon": 0.02026000000000018
      },
      {
        "episode": 444,
        "reward": 9.7,
        "loss": 1.5146129380243427e-28,
        "steps": 4,
        "epsilon": 0.02008000000000018
      },
      {
        "episode": 445,
        "reward": 9.7,
        "loss": 1.33317492982351e-28,
        "steps": 4,
        "epsilon": 0.01990000000000018
      },
      {
        "episode": 446,
        "reward": 9.7,
        "loss": 1.1675141397270975e-28,
        "steps": 4,
        "epsilon": 0.019720000000000182
      },
      {
        "episode": 447,
        "reward": 9.7,
        "loss": 1.0176305677351052e-28,
        "steps": 4,
        "epsilon": 0.019540000000000182
      },
      {
        "episode": 448,
        "reward": 9.7,
        "loss": 8.835242138475332e-29,
        "steps": 4,
        "epsilon": 0.019360000000000183
      },
      {
        "episode": 449,
        "reward": 9.7,
        "loss": 7.651950780643815e-29,
        "steps": 4,
        "epsilon": 0.019180000000000183
      },
      {
        "episode": 450,
        "reward": 9.7,
        "loss": 6.626431603856499e-29,
        "steps": 4,
        "epsilon": 0.019000000000000183
      },
      {
        "episode": 451,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.018820000000000184
      },
      {
        "episode": 452,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.018640000000000184
      },
      {
        "episode": 453,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.018460000000000185
      },
      {
        "episode": 454,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.018280000000000185
      },
      {
        "episode": 455,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.018100000000000185
      },
      {
        "episode": 456,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.017920000000000186
      },
      {
        "episode": 457,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.017740000000000186
      },
      {
        "episode": 458,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.017560000000000187
      },
      {
        "episode": 459,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.017380000000000187
      },
      {
        "episode": 460,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.017200000000000187
      },
      {
        "episode": 461,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.017020000000000188
      },
      {
        "episode": 462,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.016840000000000188
      },
      {
        "episode": 463,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.01666000000000019
      },
      {
        "episode": 464,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.01648000000000019
      },
      {
        "episode": 465,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.01630000000000019
      },
      {
        "episode": 466,
        "reward": 9.5,
        "loss": 7.753763310084044,
        "steps": 6,
        "epsilon": 0.01612000000000019
      },
      {
        "episode": 467,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.01594000000000019
      },
      {
        "episode": 468,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.01576000000000019
      },
      {
        "episode": 469,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.015580000000000191
      },
      {
        "episode": 470,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.015400000000000191
      },
      {
        "episode": 471,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.015220000000000192
      },
      {
        "episode": 472,
        "reward": 9.2,
        "loss": 3.3149112198654658,
        "steps": 5,
        "epsilon": 0.015040000000000192
      },
      {
        "episode": 473,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.014860000000000192
      },
      {
        "episode": 474,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.014680000000000193
      },
      {
        "episode": 475,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.014500000000000193
      },
      {
        "episode": 476,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.014320000000000194
      },
      {
        "episode": 477,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.014140000000000194
      },
      {
        "episode": 478,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.013960000000000194
      },
      {
        "episode": 479,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.013780000000000195
      },
      {
        "episode": 480,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.013600000000000195
      },
      {
        "episode": 481,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.013420000000000196
      },
      {
        "episode": 482,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.013240000000000196
      },
      {
        "episode": 483,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.013060000000000196
      },
      {
        "episode": 484,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.012880000000000197
      },
      {
        "episode": 485,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.012700000000000197
      },
      {
        "episode": 486,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.012520000000000198
      },
      {
        "episode": 487,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.012340000000000198
      },
      {
        "episode": 488,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.012160000000000198
      },
      {
        "episode": 489,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.011980000000000199
      },
      {
        "episode": 490,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.0118000000000002
      },
      {
        "episode": 491,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.0116200000000002
      },
      {
        "episode": 492,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.0114400000000002
      },
      {
        "episode": 493,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.0112600000000002
      },
      {
        "episode": 494,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.0110800000000002
      },
      {
        "episode": 495,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.010900000000000201
      },
      {
        "episode": 496,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.010720000000000202
      },
      {
        "episode": 497,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.010540000000000202
      },
      {
        "episode": 498,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.010360000000000202
      },
      {
        "episode": 499,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.010180000000000203
      },
      {
        "episode": 500,
        "reward": 9.7,
        "loss": 5.758684608113386e-29,
        "steps": 4,
        "epsilon": 0.010000000000000203
      }
    ]
  },
  "resultats_eval": {
    "avg_reward": 9.700000000000003,
    "std_reward": 3.552713678800501e-15,
    "avg_steps": 4.0,
    "learning_curve": [
      4.000000000000002,
      1.0000000000000053,
      7.8,
      8.5,
      9.2,
      9.3,
      8.1,
      9.7,
      9.5,
      8.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.5,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.5,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.0,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.5,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.2,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.5,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.0,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.0,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7
    ]
  },
  "score": 9.700000000000003,
  "reward_final": null,
  "eval_metrics": {
    "avg_reward": 9.700000000000003,
    "min_reward": null,
    "max_reward": null,
    "iterations": null,
    "execution_time": null,
    "learning_curve": [
      4.000000000000002,
      1.0000000000000053,
      7.8,
      8.5,
      9.2,
      9.3,
      8.1,
      9.7,
      9.5,
      8.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.5,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.5,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.0,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.5,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.2,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.5,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.0,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      8.6,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.0,
      9.7,
      9.7,
      9.7,
      9.7,
      9.3,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.5,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.2,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7,
      9.7
    ]
  }
}
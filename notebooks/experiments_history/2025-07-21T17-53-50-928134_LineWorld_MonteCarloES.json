{
  "datetime": "2025-07-21T17:53:50.928134",
  "environnement": "LineWorld",
  "modele": "MonteCarloES",
  "hyperparametres": {
    "gamma": 0.99,
    "epsilon": 0.1,
    "num_episodes": 100
  },
  "resultats_train": {
    "Q": [
      [
        1.0,
        0.99
      ],
      [
        1.0,
        0.9801000000000001
      ],
      [
        0.9899999999999994,
        0.9702989999999999
      ],
      [
        0.9801,
        0.9675267171428571
      ],
      [
        0.9702989999999999,
        0.9801000000000001
      ],
      [
        0.9702989999999999,
        0.9899999999999994
      ],
      [
        0.9801000000000001,
        1.0
      ],
      [
        0.9900000000000001,
        1.0
      ]
    ],
    "policy": [
      0,
      0,
      0,
      0,
      1,
      1,
      1,
      0
    ],
    "history": [
      {
        "episode": 1,
        "avg_q_value": 0.0625,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 1
      },
      {
        "episode": 5,
        "avg_q_value": 0.368812188125,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 6
      },
      {
        "episode": 10,
        "avg_q_value": 0.615087125625,
        "max_q_value": 1.0,
        "episode_length": 5,
        "num_state_actions_visited": 10
      },
      {
        "episode": 15,
        "avg_q_value": 0.7388371256249999,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 12
      },
      {
        "episode": 20,
        "avg_q_value": 0.8625933756249999,
        "max_q_value": 1.0,
        "episode_length": 3,
        "num_state_actions_visited": 14
      },
      {
        "episode": 25,
        "avg_q_value": 0.8625933756249999,
        "max_q_value": 1.0,
        "episode_length": 2,
        "num_state_actions_visited": 14
      },
      {
        "episode": 30,
        "avg_q_value": 0.86279552125,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 14
      },
      {
        "episode": 35,
        "avg_q_value": 0.9240517712499999,
        "max_q_value": 1.0,
        "episode_length": 3,
        "num_state_actions_visited": 15
      },
      {
        "episode": 40,
        "avg_q_value": 0.9240517712499999,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 15
      },
      {
        "episode": 45,
        "avg_q_value": 0.9241528440625,
        "max_q_value": 1.0,
        "episode_length": 2,
        "num_state_actions_visited": 15
      },
      {
        "episode": 50,
        "avg_q_value": 0.92421348775,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 15
      },
      {
        "episode": 55,
        "avg_q_value": 0.92421348775,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 15
      },
      {
        "episode": 60,
        "avg_q_value": 0.9242134877499999,
        "max_q_value": 1.0,
        "episode_length": 2,
        "num_state_actions_visited": 15
      },
      {
        "episode": 65,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 70,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 16
      },
      {
        "episode": 75,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 80,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      },
      {
        "episode": 85,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 3,
        "num_state_actions_visited": 16
      },
      {
        "episode": 90,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 1,
        "num_state_actions_visited": 16
      },
      {
        "episode": 95,
        "avg_q_value": 0.9848571752499999,
        "max_q_value": 1.0,
        "episode_length": 2,
        "num_state_actions_visited": 16
      },
      {
        "episode": 100,
        "avg_q_value": 0.9849264823214284,
        "max_q_value": 1.0,
        "episode_length": 4,
        "num_state_actions_visited": 16
      }
    ],
    "episodes": 100,
    "returns_sum": {
      "(0, 0)": 9.0,
      "(1, 0)": 37.0,
      "(2, 0)": 28.709999999999983,
      "(3, 0)": 18.6219,
      "(4, 0)": 6.7920929999999995,
      "(3, 1)": 6.772687019999999,
      "(6, 1)": 43.0,
      "(0, 1)": 4.95,
      "(2, 1)": 8.732690999999999,
      "(1, 1)": 6.8607000000000005,
      "(5, 1)": 28.709999999999983,
      "(7, 0)": 5.94,
      "(7, 1)": 11.0,
      "(4, 1)": 12.7413,
      "(6, 0)": 6.8607000000000005,
      "(5, 0)": 2.910897
    },
    "returns_count": {
      "(0, 0)": 9,
      "(1, 0)": 37,
      "(2, 0)": 29,
      "(3, 0)": 19,
      "(4, 0)": 7,
      "(3, 1)": 7,
      "(6, 1)": 43,
      "(0, 1)": 5,
      "(2, 1)": 9,
      "(1, 1)": 7,
      "(5, 1)": 29,
      "(7, 0)": 6,
      "(7, 1)": 11,
      "(4, 1)": 13,
      "(6, 0)": 7,
      "(5, 0)": 3
    }
  },
  "resultats_eval": {
    "avg_reward": 3.0,
    "min_reward": 3.0,
    "max_reward": 3.0,
    "execution_time": 0.00024437904357910156,
    "learning_curve": [
      0.0625,
      0.368812188125,
      0.615087125625,
      0.7388371256249999,
      0.8625933756249999,
      0.8625933756249999,
      0.86279552125,
      0.9240517712499999,
      0.9240517712499999,
      0.9241528440625,
      0.92421348775,
      0.92421348775,
      0.9242134877499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9849264823214284
    ],
    "rewards": [
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0
    ],
    "steps_per_episode": [
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3,
      3
    ]
  },
  "score": 3.0,
  "reward_final": null,
  "eval_metrics": {
    "avg_reward": 3.0,
    "min_reward": 3.0,
    "max_reward": 3.0,
    "iterations": null,
    "execution_time": 0.00024437904357910156,
    "learning_curve": [
      0.0625,
      0.368812188125,
      0.615087125625,
      0.7388371256249999,
      0.8625933756249999,
      0.8625933756249999,
      0.86279552125,
      0.9240517712499999,
      0.9240517712499999,
      0.9241528440625,
      0.92421348775,
      0.92421348775,
      0.9242134877499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9848571752499999,
      0.9849264823214284
    ]
  }
}
{
  "datetime": "2025-07-21T17:16:44.426111",
  "environnement": "LineWorld",
  "modele": "QLearning",
  "hyperparametres": {
    "gamma": 0.99,
    "alpha": 0.1,
    "epsilon": 0.11,
    "num_episodes": 100
  },
  "resultats_train": {
    "Q": [
      [
        0.0,
        0.0
      ],
      [
        -0.1,
        0.0
      ],
      [
        -0.1,
        0.0
      ],
      [
        -0.1,
        0.2800175265881348
      ],
      [
        -0.19,
        2.968062997809334
      ],
      [
        0.5841470864448539,
        1.989701594163925
      ],
      [
        0.2691273117373936,
        0.9999704873345693
      ],
      [
        0.0,
        0.0
      ]
    ],
    "policy": [
      0,
      1,
      1,
      1,
      1,
      1,
      1,
      0
    ],
    "history": [
      {
        "episode": 1,
        "reward": 3.0,
        "loss": 0.9243602,
        "steps": 5,
        "epsilon": 0.109
      },
      {
        "episode": 2,
        "reward": 3.0,
        "loss": 0.94008087,
        "steps": 3,
        "epsilon": 0.108
      },
      {
        "episode": 3,
        "reward": 3.0,
        "loss": 0.8741578989870001,
        "steps": 3,
        "epsilon": 0.107
      },
      {
        "episode": 4,
        "reward": 3.0,
        "loss": 0.81417024971883,
        "steps": 3,
        "epsilon": 0.106
      },
      {
        "episode": 5,
        "reward": 3.0,
        "loss": 0.7587096440328972,
        "steps": 3,
        "epsilon": 0.105
      },
      {
        "episode": 6,
        "reward": 3.0,
        "loss": 0.706838144343199,
        "steps": 3,
        "epsilon": 0.104
      },
      {
        "episode": 7,
        "reward": 3.0,
        "loss": 0.6579393988358377,
        "steps": 3,
        "epsilon": 0.103
      },
      {
        "episode": 8,
        "reward": 3.0,
        "loss": 0.611615652906823,
        "steps": 3,
        "epsilon": 0.102
      },
      {
        "episode": 9,
        "reward": 3.0,
        "loss": 0.5676161955027591,
        "steps": 3,
        "epsilon": 0.10099999999999999
      },
      {
        "episode": 10,
        "reward": 3.0,
        "loss": 0.5257874892169198,
        "steps": 3,
        "epsilon": 0.09999999999999999
      },
      {
        "episode": 11,
        "reward": 3.0,
        "loss": 0.48603834934253515,
        "steps": 3,
        "epsilon": 0.09899999999999999
      },
      {
        "episode": 12,
        "reward": 3.0,
        "loss": 0.4483156483976436,
        "steps": 3,
        "epsilon": 0.09799999999999999
      },
      {
        "episode": 13,
        "reward": 3.0,
        "loss": 0.4125874481952326,
        "steps": 3,
        "epsilon": 0.09699999999999999
      },
      {
        "episode": 14,
        "reward": 3.0,
        "loss": 0.3788314221260496,
        "steps": 3,
        "epsilon": 0.09599999999999999
      },
      {
        "episode": 15,
        "reward": 3.0,
        "loss": 0.3470270775943211,
        "steps": 3,
        "epsilon": 0.09499999999999999
      },
      {
        "episode": 16,
        "reward": 3.0,
        "loss": 0.3171507259033747,
        "steps": 3,
        "epsilon": 0.09399999999999999
      },
      {
        "episode": 17,
        "reward": 3.0,
        "loss": 0.28917244430083144,
        "steps": 3,
        "epsilon": 0.09299999999999999
      },
      {
        "episode": 18,
        "reward": 4.0,
        "loss": 0.8018893660939321,
        "steps": 5,
        "epsilon": 0.09199999999999998
      },
      {
        "episode": 19,
        "reward": 3.0,
        "loss": 0.2086098582030351,
        "steps": 3,
        "epsilon": 0.09099999999999998
      },
      {
        "episode": 20,
        "reward": 3.0,
        "loss": 0.19008198271605625,
        "steps": 3,
        "epsilon": 0.08999999999999998
      },
      {
        "episode": 21,
        "reward": 4.0,
        "loss": 0.7752292262406447,
        "steps": 5,
        "epsilon": 0.08899999999999998
      },
      {
        "episode": 22,
        "reward": 3.0,
        "loss": 0.13674120765202208,
        "steps": 3,
        "epsilon": 0.08799999999999998
      },
      {
        "episode": 23,
        "reward": 3.0,
        "loss": 0.12442392723037632,
        "steps": 3,
        "epsilon": 0.08699999999999998
      },
      {
        "episode": 24,
        "reward": 3.0,
        "loss": 0.11291589343255394,
        "steps": 3,
        "epsilon": 0.08599999999999998
      },
      {
        "episode": 25,
        "reward": 3.0,
        "loss": 0.10220812160525393,
        "steps": 3,
        "epsilon": 0.08499999999999998
      },
      {
        "episode": 26,
        "reward": 3.0,
        "loss": 0.092284416137844,
        "steps": 3,
        "epsilon": 0.08399999999999998
      },
      {
        "episode": 27,
        "reward": 3.0,
        "loss": 0.08312235964407812,
        "steps": 3,
        "epsilon": 0.08299999999999998
      },
      {
        "episode": 28,
        "reward": 3.0,
        "loss": 0.07469435862325823,
        "steps": 3,
        "epsilon": 0.08199999999999998
      },
      {
        "episode": 29,
        "reward": 3.0,
        "loss": 0.06696868761730863,
        "steps": 3,
        "epsilon": 0.08099999999999997
      },
      {
        "episode": 30,
        "reward": 3.0,
        "loss": 0.059910489939174784,
        "steps": 3,
        "epsilon": 0.07999999999999997
      },
      {
        "episode": 31,
        "reward": 3.0,
        "loss": 0.053482706248994365,
        "steps": 3,
        "epsilon": 0.07899999999999997
      },
      {
        "episode": 32,
        "reward": 3.0,
        "loss": 0.047646912879463564,
        "steps": 3,
        "epsilon": 0.07799999999999997
      },
      {
        "episode": 33,
        "reward": 3.0,
        "loss": 0.04236406016893104,
        "steps": 3,
        "epsilon": 0.07699999999999997
      },
      {
        "episode": 34,
        "reward": 3.0,
        "loss": 0.03759510746342778,
        "steps": 3,
        "epsilon": 0.07599999999999997
      },
      {
        "episode": 35,
        "reward": 3.0,
        "loss": 0.03330155620062309,
        "steps": 3,
        "epsilon": 0.07499999999999997
      },
      {
        "episode": 36,
        "reward": 3.0,
        "loss": 0.029445885872889654,
        "steps": 3,
        "epsilon": 0.07399999999999997
      },
      {
        "episode": 37,
        "reward": 3.0,
        "loss": 0.02599189994006335,
        "steps": 3,
        "epsilon": 0.07299999999999997
      },
      {
        "episode": 38,
        "reward": 3.0,
        "loss": 0.022904990152226006,
        "steps": 3,
        "epsilon": 0.07199999999999997
      },
      {
        "episode": 39,
        "reward": 3.0,
        "loss": 0.020152328445541354,
        "steps": 3,
        "epsilon": 0.07099999999999997
      },
      {
        "episode": 40,
        "reward": 3.0,
        "loss": 0.01770299575668931,
        "steps": 3,
        "epsilon": 0.06999999999999997
      },
      {
        "episode": 41,
        "reward": 3.0,
        "loss": 0.0155280569028167,
        "steps": 3,
        "epsilon": 0.06899999999999996
      },
      {
        "episode": 42,
        "reward": 3.0,
        "loss": 0.013600590207844246,
        "steps": 3,
        "epsilon": 0.06799999999999996
      },
      {
        "episode": 43,
        "reward": 3.0,
        "loss": 0.01189567991370094,
        "steps": 3,
        "epsilon": 0.06699999999999996
      },
      {
        "episode": 44,
        "reward": 3.0,
        "loss": 0.01039037866837549,
        "steps": 3,
        "epsilon": 0.06599999999999996
      },
      {
        "episode": 45,
        "reward": 3.0,
        "loss": 0.009063646586754176,
        "steps": 3,
        "epsilon": 0.06499999999999996
      },
      {
        "episode": 46,
        "reward": 3.0,
        "loss": 0.007896272576352031,
        "steps": 3,
        "epsilon": 0.06399999999999996
      },
      {
        "episode": 47,
        "reward": -4.0,
        "loss": 1.0,
        "steps": 4,
        "epsilon": 0.06299999999999996
      },
      {
        "episode": 48,
        "reward": 4.0,
        "loss": 1.182703323267373,
        "steps": 5,
        "epsilon": 0.06199999999999996
      },
      {
        "episode": 49,
        "reward": 3.0,
        "loss": 0.004991852629681094,
        "steps": 3,
        "epsilon": 0.06099999999999996
      },
      {
        "episode": 50,
        "reward": 3.0,
        "loss": 0.004359171928261493,
        "steps": 3,
        "epsilon": 0.059999999999999956
      },
      {
        "episode": 51,
        "reward": 2.0,
        "loss": 1.7324771136441321,
        "steps": 5,
        "epsilon": 0.058999999999999955
      },
      {
        "episode": 52,
        "reward": 3.0,
        "loss": 0.0033104333520521394,
        "steps": 3,
        "epsilon": 0.057999999999999954
      },
      {
        "episode": 53,
        "reward": 3.0,
        "loss": 0.27579028918215653,
        "steps": 7,
        "epsilon": 0.056999999999999953
      },
      {
        "episode": 54,
        "reward": 3.0,
        "loss": 0.0027027882931559845,
        "steps": 3,
        "epsilon": 0.05599999999999995
      },
      {
        "episode": 55,
        "reward": 3.0,
        "loss": 0.0023127986760121248,
        "steps": 3,
        "epsilon": 0.05499999999999995
      },
      {
        "episode": 56,
        "reward": 3.0,
        "loss": 0.0019782335048011503,
        "steps": 3,
        "epsilon": 0.05399999999999995
      },
      {
        "episode": 57,
        "reward": 3.0,
        "loss": 0.001691333721832919,
        "steps": 3,
        "epsilon": 0.05299999999999995
      },
      {
        "episode": 58,
        "reward": 3.0,
        "loss": 0.0014454118693318708,
        "steps": 3,
        "epsilon": 0.05199999999999995
      },
      {
        "episode": 59,
        "reward": 3.0,
        "loss": 0.0012347054813035706,
        "steps": 3,
        "epsilon": 0.05099999999999995
      },
      {
        "episode": 60,
        "reward": 3.0,
        "loss": 0.0010542505161550315,
        "steps": 3,
        "epsilon": 0.04999999999999995
      },
      {
        "episode": 61,
        "reward": 3.0,
        "loss": 0.0008997720506171183,
        "steps": 3,
        "epsilon": 0.048999999999999946
      },
      {
        "episode": 62,
        "reward": 3.0,
        "loss": 0.0007675898557569677,
        "steps": 3,
        "epsilon": 0.047999999999999945
      },
      {
        "episode": 63,
        "reward": 3.0,
        "loss": 0.0006545368146347488,
        "steps": 3,
        "epsilon": 0.046999999999999945
      },
      {
        "episode": 64,
        "reward": 3.0,
        "loss": 0.0005578884287215428,
        "steps": 3,
        "epsilon": 0.045999999999999944
      },
      {
        "episode": 65,
        "reward": 3.0,
        "loss": 0.0004753019049590714,
        "steps": 3,
        "epsilon": 0.04499999999999994
      },
      {
        "episode": 66,
        "reward": 3.0,
        "loss": 0.00040476352419989203,
        "steps": 3,
        "epsilon": 0.04399999999999994
      },
      {
        "episode": 67,
        "reward": 3.0,
        "loss": 0.00034454317040657893,
        "steps": 3,
        "epsilon": 0.04299999999999994
      },
      {
        "episode": 68,
        "reward": 3.0,
        "loss": 0.0002931550531043349,
        "steps": 3,
        "epsilon": 0.04199999999999994
      },
      {
        "episode": 69,
        "reward": 3.0,
        "loss": 0.0002493237870774817,
        "steps": 3,
        "epsilon": 0.04099999999999994
      },
      {
        "episode": 70,
        "reward": 3.0,
        "loss": 0.0002119551064239567,
        "steps": 3,
        "epsilon": 0.03999999999999994
      },
      {
        "episode": 71,
        "reward": 3.0,
        "loss": 0.00018011058754984258,
        "steps": 3,
        "epsilon": 0.03899999999999994
      },
      {
        "episode": 72,
        "reward": 3.0,
        "loss": 0.14792711783484608,
        "steps": 5,
        "epsilon": 0.03799999999999994
      },
      {
        "episode": 73,
        "reward": 3.0,
        "loss": 0.0001341216693464525,
        "steps": 3,
        "epsilon": 0.036999999999999936
      },
      {
        "episode": 74,
        "reward": 3.0,
        "loss": 0.00011325680618492817,
        "steps": 3,
        "epsilon": 0.035999999999999935
      },
      {
        "episode": 75,
        "reward": 3.0,
        "loss": 0.12025072686660447,
        "steps": 5,
        "epsilon": 0.034999999999999934
      },
      {
        "episode": 76,
        "reward": 3.0,
        "loss": 8.309403896602663e-05,
        "steps": 3,
        "epsilon": 0.03399999999999993
      },
      {
        "episode": 77,
        "reward": 3.0,
        "loss": 6.981457931266338e-05,
        "steps": 3,
        "epsilon": 0.03299999999999993
      },
      {
        "episode": 78,
        "reward": 3.0,
        "loss": 5.865394419848261e-05,
        "steps": 3,
        "epsilon": 0.03199999999999993
      },
      {
        "episode": 79,
        "reward": 3.0,
        "loss": 4.927417664753023e-05,
        "steps": 3,
        "epsilon": 0.03099999999999993
      },
      {
        "episode": 80,
        "reward": 3.0,
        "loss": 4.139129716549847e-05,
        "steps": 3,
        "epsilon": 0.02999999999999993
      },
      {
        "episode": 81,
        "reward": 3.0,
        "loss": 3.476665214172432e-05,
        "steps": 3,
        "epsilon": 0.02899999999999993
      },
      {
        "episode": 82,
        "reward": 3.0,
        "loss": 2.919965762646387e-05,
        "steps": 3,
        "epsilon": 0.027999999999999928
      },
      {
        "episode": 83,
        "reward": 3.0,
        "loss": 2.452171129090149e-05,
        "steps": 3,
        "epsilon": 0.026999999999999927
      },
      {
        "episode": 84,
        "reward": 3.0,
        "loss": 2.0591082854531236e-05,
        "steps": 3,
        "epsilon": 0.025999999999999926
      },
      {
        "episode": 85,
        "reward": 3.0,
        "loss": 1.7288624454838967e-05,
        "steps": 3,
        "epsilon": 0.024999999999999925
      },
      {
        "episode": 86,
        "reward": 3.0,
        "loss": 1.4514168414192101e-05,
        "steps": 3,
        "epsilon": 0.023999999999999924
      },
      {
        "episode": 87,
        "reward": 3.0,
        "loss": 1.2183501515761184e-05,
        "steps": 3,
        "epsilon": 0.022999999999999923
      },
      {
        "episode": 88,
        "reward": 3.0,
        "loss": 1.0225822967517163e-05,
        "steps": 3,
        "epsilon": 0.021999999999999922
      },
      {
        "episode": 89,
        "reward": 3.0,
        "loss": 8.581608316230538e-06,
        "steps": 3,
        "epsilon": 0.02099999999999992
      },
      {
        "episode": 90,
        "reward": 3.0,
        "loss": 7.200814173976215e-06,
        "steps": 3,
        "epsilon": 0.01999999999999992
      },
      {
        "episode": 91,
        "reward": 3.0,
        "loss": 6.041369153027719e-06,
        "steps": 3,
        "epsilon": 0.01899999999999992
      },
      {
        "episode": 92,
        "reward": 3.0,
        "loss": 5.067905215727995e-06,
        "steps": 3,
        "epsilon": 0.01799999999999992
      },
      {
        "episode": 93,
        "reward": 3.0,
        "loss": 4.250691020053748e-06,
        "steps": 3,
        "epsilon": 0.016999999999999918
      },
      {
        "episode": 94,
        "reward": 3.0,
        "loss": 3.5647350166240743e-06,
        "steps": 3,
        "epsilon": 0.015999999999999917
      },
      {
        "episode": 95,
        "reward": 3.0,
        "loss": 2.9890312264808975e-06,
        "steps": 3,
        "epsilon": 0.014999999999999916
      },
      {
        "episode": 96,
        "reward": 3.0,
        "loss": 2.5059249656134444e-06,
        "steps": 3,
        "epsilon": 0.013999999999999915
      },
      {
        "episode": 97,
        "reward": 3.0,
        "loss": 2.1005794188125807e-06,
        "steps": 3,
        "epsilon": 0.012999999999999914
      },
      {
        "episode": 98,
        "reward": 3.0,
        "loss": 1.7605270163660778e-06,
        "steps": 3,
        "epsilon": 0.011999999999999914
      },
      {
        "episode": 99,
        "reward": 3.0,
        "loss": 1.4752921275926986e-06,
        "steps": 3,
        "epsilon": 0.010999999999999913
      },
      {
        "episode": 100,
        "reward": 3.0,
        "loss": 1.2360737348825924e-06,
        "steps": 3,
        "epsilon": 0.01
      }
    ]
  },
  "resultats_eval": {
    "avg_reward": 3.0,
    "std_reward": 0.0,
    "avg_steps": 3.0,
    "learning_curve": [
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      4.0,
      3.0,
      3.0,
      4.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      -4.0,
      4.0,
      3.0,
      3.0,
      2.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0
    ]
  },
  "score": 3.0,
  "reward_final": null,
  "eval_metrics": {
    "avg_reward": 3.0,
    "min_reward": null,
    "max_reward": null,
    "iterations": null,
    "execution_time": null,
    "learning_curve": [
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      4.0,
      3.0,
      3.0,
      4.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      -4.0,
      4.0,
      3.0,
      3.0,
      2.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0,
      3.0
    ]
  }
}